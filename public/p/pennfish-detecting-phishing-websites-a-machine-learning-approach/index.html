<!DOCTYPE html>
<html lang="en-us" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content="PennFish: Detecting Phishing Websites - A Machine Learning Approach">
<title>PennFish: Detecting Phishing Websites - A Machine Learning Approach</title>

<link rel='canonical' href='https://www.seas.upenn.edu/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/'>

<link rel="stylesheet" href="/~jimy/pennfish/scss/style.min.8e60baf4cd3fc55968717a6e39762f4d28ed7ef6007566b6c7970ad0fe907198.css"><meta property='og:title' content="PennFish: Detecting Phishing Websites - A Machine Learning Approach">
<meta property='og:description' content="PennFish: Detecting Phishing Websites - A Machine Learning Approach">
<meta property='og:url' content='https://www.seas.upenn.edu/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/'>
<meta property='og:site_name' content='PennFish'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='Phishing' /><meta property='article:published_time' content='2024-04-23T00:00:00&#43;00:00'/><meta property='article:modified_time' content='2024-04-23T00:00:00&#43;00:00'/><meta property='og:image' content='https://www.seas.upenn.edu/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/PennFish_Detecting_Phishing_Websites_-_A_Machine_Learning_Approach.jpg' />
<meta name="twitter:title" content="PennFish: Detecting Phishing Websites - A Machine Learning Approach">
<meta name="twitter:description" content="PennFish: Detecting Phishing Websites - A Machine Learning Approach"><meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content='https://www.seas.upenn.edu/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/PennFish_Detecting_Phishing_Websites_-_A_Machine_Learning_Approach.jpg' />
    <link rel="shortcut icon" href="/favicon.png" />

  


    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/~jimy/pennfish">PennFish</a></h1>
            <h2 class="site-description">PennFish: Detecting Phishing Websites - A Machine Learning Approach</h2>
        </div>
    </header><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/~jimy/pennfish/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>Home</span>
            </a>
        </li>
        
        
        <li >
            <a href='/~jimy/pennfish/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>Archives</span>
            </a>
        </li>
        
        
        <li >
            <a href='/~jimy/pennfish/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        
        <li class="menu-bottom-section">
            <ol class="menu">

                
                    <li id="dark-mode-toggle">
                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <span>Dark Mode</span>
                    </li>
                
            </ol>
        </li>
    </ol>
</aside>

    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        <div class="widget-icon">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



        </div>
        <h2 class="widget-title section-title">Table of contents</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ol>
    <li><a href="#pennfish-web-app-demo">Pennfish Web App Demo</a></li>
    <li><a href="#background">Background</a>
      <ol>
        <li><a href="#need-for-advanced-detection-systems"><strong>Need for Advanced Detection Systems</strong></a></li>
        <li><a href="#a-machine-learning-approach-idea-formulation">A Machine Learning Approach: Idea Formulation</a></li>
      </ol>
    </li>
    <li><a href="#project-overview">Project Overview</a></li>
    <li><a href="#dive-into-the-datasets">Dive into the Datasets</a>
      <ol>
        <li><a href="#dataset-selection">Dataset Selection</a></li>
        <li><a href="#features-of-the-original-dataset">Features of the Original Dataset</a></li>
        <li><a href="#data-cleaning">Data Cleaning</a></li>
        <li><a href="#integrating-the-public-suffix-list-data">Integrating the Public Suffix List Data</a>
          <ol>
            <li><a href="#what-is-the-psl"><strong>What is the PSL?</strong></a></li>
            <li><a href="#what-is-etld"><strong>What is eTLD?</strong></a></li>
            <li><a href="#eda-implications"><strong>EDA implications</strong></a></li>
            <li><a href="#integrating-the-psl-data">Integrating the PSL Data</a></li>
          </ol>
        </li>
        <li><a href="#integrating-the-domain-pricing-data">Integrating the Domain Pricing Data</a>
          <ol>
            <li><a href="#background-on-pricing-of-domain-names">Background on Pricing of Domain Names</a></li>
            <li><a href="#acquire-pricing-data-of-domain-names">Acquire Pricing Data of Domain Names</a></li>
            <li><a href="#acquiring-the-domain-market-data">Acquiring the Domain Market Data</a></li>
            <li><a href="#convert-the-idn-domains-punycode">Convert the IDN Domains (Punycode)</a></li>
            <li><a href="#join-the-tld-pricing-data-with-df_features">Join the TLD Pricing Data with <code>df_features</code></a></li>
          </ol>
        </li>
        <li><a href="#remove-unnecessary-labels">Remove Unnecessary Labels</a></li>
        <li><a href="#understanding-features-input-data">Understanding Features (Input) Data</a>
          <ol>
            <li><a href="#split-numerical-and-categorical-input-features">Split numerical and categorical input features</a></li>
          </ol>
        </li>
        <li><a href="#one-hot-encoding"><strong>One Hot Encoding</strong></a></li>
        <li><a href="#completing-the-preprocessing-steps">Completing the Preprocessing Steps</a></li>
      </ol>
    </li>
    <li><a href="#exploratory-data-analysis"><strong>Exploratory Data Analysis</strong></a>
      <ol>
        <li><a href="#install-dependencies">Install Dependencies</a></li>
        <li><a href="#understanding-target-data">Understanding Target Data</a>
          <ol>
            <li><a href="#number-of-phishing-vs-legitimate-data">Number of phishing vs legitimate data</a></li>
          </ol>
        </li>
        <li><a href="#understanding-numerical-features">Understanding Numerical Features</a>
          <ol>
            <li><a href="#correlation-matrix">Correlation Matrix</a></li>
            <li><a href="#violin-plots"><strong>Violin Plots</strong></a></li>
            <li><a href="#interactive-box-plots">Interactive Box Plots</a></li>
            <li><a href="#statistical-tests">Statistical Tests</a></li>
            <li><a href="#most-important-numerical-features">Most Important Numerical Features</a></li>
            <li><a href="#weakest-numerical-features">Weakest Numerical Features</a></li>
          </ol>
        </li>
        <li><a href="#understanding-categorical-features">Understanding Categorical Features</a></li>
        <li><a href="#statistical-testing-for-categorical-features">Statistical Testing for Categorical Features</a></li>
        <li><a href="#tld-phishing-abuse-analysis-over-the-tld-field">TLD Phishing Abuse Analysis over the <code>TLD</code> field</a></li>
        <li><a href="#the-most-abused-cctlds-country-code-tlds">The Most Abused ccTLDs (country code TLDs)</a>
          <ol>
            <li><a href="#global-heat-map-of-cctld-phishing-abuse-counts">Global Heat Map of ccTLD Phishing Abuse Counts</a></li>
          </ol>
        </li>
      </ol>
    </li>
    <li><a href="#logistic-regression"><strong>Logistic Regression</strong></a>
      <ol>
        <li><a href="#pca-to-reduce-dimensionality"><strong>PCA to Reduce Dimensionality</strong></a></li>
      </ol>
    </li>
    <li><a href="#logistic-regression-with-pca"><strong>Logistic Regression with PCA</strong></a></li>
    <li><a href="#ridge-regression"><strong>Ridge Regression</strong></a></li>
    <li><a href="#linear-regression-unregularized"><strong>Linear Regression (Unregularized)</strong></a></li>
    <li><a href="#linear-regression-unregularized-with-pca"><strong>Linear Regression (Unregularized) with PCA</strong></a></li>
    <li><a href="#random-forest-classifier"><strong>Random Forest Classifier</strong></a></li>
    <li><a href="#random-forest-regression"><strong>Random Forest Regression</strong></a></li>
    <li><a href="#decision-tree-classifier"><strong>Decision Tree classifier</strong></a>
      <ol>
        <li><a href="#preprocessing-and-pca">Preprocessing and PCA</a>
          <ol>
            <li><a href="#splitting-training-data">Splitting Training Data</a></li>
          </ol>
        </li>
        <li><a href="#decision-tree">Decision tree</a>
          <ol>
            <li><a href="#optimizing-decision-tree-depth"><strong>Optimizing Decision Tree Depth</strong></a></li>
          </ol>
        </li>
        <li><a href="#bagging">Bagging</a></li>
      </ol>
    </li>
    <li><a href="#k-nearest-neighbor-knn"><strong>K Nearest Neighbor (KNN)</strong></a>
      <ol>
        <li>
          <ol>
            <li><a href="#optimizing-knn-parameters"><strong>Optimizing KNN Parameters</strong></a></li>
          </ol>
        </li>
      </ol>
    </li>
    <li><a href="#discriminant-analysis"><strong>Discriminant Analysis</strong></a>
      <ol>
        <li><a href="#lda">LDA</a>
          <ol>
            <li><a href="#optimizing-lda-with-cross-validation"><strong>Optimizing LDA with Cross Validation</strong></a></li>
          </ol>
        </li>
        <li><a href="#quadratic-discriminant-analysis-qda"><strong>Quadratic Discriminant Analysis (QDA)</strong></a></li>
      </ol>
    </li>
    <li><a href="#support-vector-machine-svm"><strong>Support Vector Machine (SVM)</strong></a>
      <ol>
        <li>
          <ol>
            <li><a href="#exploring-svm-with-rbf-kernel"><strong>Exploring SVM with RBF Kernel</strong></a></li>
          </ol>
        </li>
        <li><a href="#conclusion-on-svm-performance"><strong>Conclusion on SVM Performance</strong></a></li>
      </ol>
    </li>
    <li><a href="#artificial-neural-networks-classification"><strong>Artificial Neural Networks Classification</strong></a>
      <ol>
        <li><a href="#introduction-to-the-ann-architecture">Introduction to the ANN Architecture</a></li>
        <li><a href="#split-data-to-train-validation-and-test"><strong>Split Data to Train, Validation, and Test</strong></a></li>
        <li><a href="#feature-scaling">Feature Scaling</a></li>
        <li><a href="#using-ann-for-binary-classification-the-baseline-model">Using ANN for Binary Classification: The Baseline Model</a>
          <ol>
            <li><a href="#build-the-baseline-model">Build the Baseline Model</a></li>
            <li><a href="#fit-the-baseline-model">Fit the Baseline Model</a></li>
            <li><a href="#validation">Validation</a></li>
            <li><a href="#test-the-baseline-model">Test the Baseline Model</a></li>
          </ol>
        </li>
        <li><a href="#improve-the-ann-model-by-tuning-the-ann-and-avoiding-overfitting">Improve the ANN Model by Tuning the ANN and Avoiding Overfitting</a>
          <ol>
            <li><a href="#set-parameters">Set Parameters</a></li>
            <li><a href="#implementing-early-stoping">Implementing Early Stoping</a></li>
            <li><a href="#implementing-a-learning-rate-schedule">Implementing <strong>a Learning Rate Schedule</strong></a></li>
            <li><a href="#implementing-the-weight-regularization">Implementing <strong>the Weight Regularization</strong></a></li>
          </ol>
        </li>
        <li><a href="#build-the-model">Build the Model</a>
          <ol>
            <li><a href="#implementing-dropout-layers">Implementing Dropout Layers</a></li>
            <li><a href="#fit-the-model"><strong>Fit the Model</strong></a></li>
            <li><a href="#validation-1">Validation</a></li>
            <li><a href="#testing-the-model"><strong>Testing the Model</strong></a></li>
            <li><a href="#make-predictions"><strong>Make Predictions</strong></a></li>
          </ol>
        </li>
        <li><a href="#evaluation"><strong>Evaluation</strong></a>
          <ol>
            <li><a href="#confusion-matrix">Confusion Matrix</a></li>
            <li><a href="#classification-report"><strong>Classification Report</strong></a></li>
            <li><a href="#roc-curve">ROC Curve</a></li>
          </ol>
        </li>
        <li><a href="#conclusion-of-ann">Conclusion of ANN</a></li>
      </ol>
    </li>
    <li><a href="#challenges">Challenges</a></li>
    <li><a href="#conclusion">Conclusion</a></li>
    <li><a href="#references">References</a></li>
  </ol>
</nav>
        </div>
    </section>

            
        
    </aside>


            <main class="main full-width">
    <article class="has-image main-article">
    <header class="article-header">
        <div class="article-image">
            <a href="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/">
                <img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/_hubf20d75a9360d414acde931a8a7f63b5_219738_e730ac67abbb14e25e0412ec1d51ae22.jpg"
                        srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/_hubf20d75a9360d414acde931a8a7f63b5_219738_e730ac67abbb14e25e0412ec1d51ae22.jpg 800w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/_hubf20d75a9360d414acde931a8a7f63b5_219738_f331e9626f9e7257e15fd1a8bb6d8ed8.jpg 1600w"
                        width="800" 
                        height="450" 
                        loading="lazy"
                        alt="Featured image of post PennFish: Detecting Phishing Websites - A Machine Learning Approach" />
                
            </a>
        </div>
    

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/~jimy/pennfish/categories/phishing/" >
                Phishing
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/">PennFish: Detecting Phishing Websites - A Machine Learning Approach</a>
        </h2>
    
        
        <h3 class="article-subtitle">
            PennFish: Detecting Phishing Websites - A Machine Learning Approach
        </h3>
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Apr 23, 23230</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    64 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <!-- ## PennFish: Detecting Phishing Websites - A Machine Learning Approach -->
<!-- ![PennFish Detecting Phishing Websites - A Machine Learning Approach.jpg](PennFish_Detecting_Phishing_Websites_-_A_Machine_Learning_Approach.jpg) -->
<p>Team Project of CIS 5450 Big Data Analytics</p>
<h2 id="pennfish-web-app-demo">
    <a href="#pennfish-web-app-demo">#</a>
    Pennfish Web App Demo
</h2><p>Screencast Video Demo:</p>
<video width="100%" autoplay loop controls>
  <source src="pennfish-app-demo.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>
<h2 id="background">
    <a href="#background">#</a>
    Background
</h2><h3 id="need-for-advanced-detection-systems">
    <a href="#need-for-advanced-detection-systems">#</a>
    <strong>Need for Advanced Detection Systems</strong>
</h3><p>In recent years, the rise of internet and cloud technologies has significantly increased the volume of  online purchases and transactions. This expansion has led to unauthorized access to sensitive user information and compromised enterprise resources. Phishing, a common type of attack, deceives users into accessing malicious content to steal their information (Dutta, 2021).</p>
<p>Often, phishing websites mimic legitimate ones in terms of their interface and URL (Levy, 2004).</p>
<p>Various methods, including blacklists and heuristic approaches, have been proposed to detect these phishing sites. However, heuristics are more effective in detecting phishing sites than blacklists due to their short lifetime and ability to distinguish legitimate from phishing sites (Gastellier-Prevost, 2011).</p>
<p>Current research indicates that the effectiveness of phishing detection systems is limited, highlighting the need for more advanced, intelligent techniques to safeguard users against these cyber threats (Dutta, 2021).</p>
<h3 id="a-machine-learning-approach-idea-formulation">
    <a href="#a-machine-learning-approach-idea-formulation">#</a>
    A Machine Learning Approach: Idea Formulation
</h3><p>ML models can learn from large amounts of data to recognize patterns that are typical of phishing sites.</p>
<p>Consider two URLs:</p>
<ul>
<li><code>https://upenn-payments.xyz/payment.php</code> and</li>
<li><code>https://srfs.upenn.edu/billing-payment/pennpay</code>.</li>
</ul>
<p>At first glance to an unsuspecting user, both might appear legitimate, but a ML model can be trained to detect phishing to evaluate their features. For instance, the domain name <code>penn-payments.xyz</code> might raise red flags as it uses a less common and perhaps sketchy top-level domain (<code>.xyz</code>) compared to the more trusted <code>.edu</code> TLD in <code>srfs.upenn.edu</code>.</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled.png"
	width="2493"
	height="241"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_hu7496195b6b5fc914f89b58c10838b807_51725_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_hu7496195b6b5fc914f89b58c10838b807_51725_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="Source: MDN (https://developer.mozilla.org/en-US/docs/Learn/Common_questions/Web_mechanics/What_is_a_URL)"
	
	
		class="gallery-image" 
		data-flex-grow="1034"
		data-flex-basis="2482px"
	
></p>
<p>Source: MDN (<a class="link" href="https://developer.mozilla.org/en-US/docs/Learn/Common_questions/Web_mechanics/What_is_a_URL"  target="_blank" rel="noopener"
    >https://developer.mozilla.org/en-US/docs/Learn/Common_questions/Web_mechanics/What_is_a_URL</a>)</p>
<p>Moreover, the first URL is shorter and lacks a path structure that implies a deeper, more organized content hierarchy as seen in the second URL with <code>/billing-payment/pennpay</code>.</p>
<p>Our assumption is that by extracting and analyzing these URL features, a machine learning model can learn to predict potential phishing threats with greater accuracy, providing a feasible and powerful tool in cybersecurity efforts.</p>
<p>We plan to use ML models to leverage these features to scrutinize URLs and identify potential phishing threats.</p>
<h2 id="project-overview">
    <a href="#project-overview">#</a>
    Project Overview
</h2><p>In our project, we&rsquo;ve used a number of machine learning approaches.</p>
<p>Here’s a brief overview:</p>
<ol>
<li><strong>Data Pre-processing</strong> -  we started the project with cleaning the data and exploring additional sources of data that we can integrate into the original dataset.</li>
<li><strong>Exploratory Data Analysis (EDA) -</strong> we explored the data to understand the characteristics and patterns that might be present.</li>
<li><strong>Feature Engineering</strong> - We modify features from the existing data to better extract patterns that can be important for phishing detection.</li>
<li><strong>Linear Regression (Unregularized)</strong> - This is a basic approach where we try to fit a straight line that predicts phishing likelihood based on input features.</li>
<li><strong>Ridge Regression</strong> - To analyze data that suffers from multicollinearity (when independent variables are highly correlated).</li>
<li><strong>Logistic Regression</strong> - A step up from linear regression, this method is specifically used for binary classification tasks like ours (phishing or not).</li>
<li><strong>PCA to Reduce Dimensionality, Logistic Regression with PCA</strong> - This approach first reduces the complexity of the data using Principal Component Analysis (PCA) and then applies logistic regression to the simplified data.</li>
<li><strong>Decision Tree Classifier</strong> - We used it to makes decisions based on asking a series of specific questions about the features of the URL.</li>
<li><strong>Random Forest Classifier</strong> - An ensemble method that uses multiple decision trees to improve the classification accuracy.</li>
<li><strong>SVM (Support Vector Machine)</strong> - A more sophisticated classification technique that finds the best boundary to differentiate between phishing and non-phishing URLs.</li>
<li><strong>Artificial Neural Network Model</strong> - We ended the project by leveraging ANN to model and predict phishing URLs, capable of capturing intricate patterns in the data.</li>
</ol>
<h2 id="dive-into-the-datasets">
    <a href="#dive-into-the-datasets">#</a>
    Dive into the Datasets
</h2><p><a class="link" href="https://archive.ics.uci.edu/dataset/967/phiusiil&#43;phishing&#43;url&#43;dataset"  target="_blank" rel="noopener"
    >UCI Machine Learning Repository</a></p>
<h3 id="dataset-selection">
    <a href="#dataset-selection">#</a>
    Dataset Selection
</h3><p>For our project on detecting phishing URLs, we chose a dataset crafted by Arvind Prasad and Shalini Chandra, as detailed in their paper titled &ldquo;<a class="link" href="https://www.sciencedirect.com/science/article/abs/pii/S0167404823004558"  target="_blank" rel="noopener"
    >PhiUSIIL: A diverse security profile empowered phishing URL detection framework based on similarity index and incremental learning</a>.&rdquo;</p>
<p>This data set was released in March 2024.</p>
<p>This dataset is specifically created for the task of phishing URL detection and includes a robust framework that leverages a similarity index. This index is quite effective in identifying visual similarity-based attacks, such as those involving zero-width characters, homographs, punycode, homophones, bit squatting, and combosquatting.</p>
<p>We selected this dataset because of its richness and the extensive range of features it offers, which are not typically available in more generic datasets such as similar ones from Kaggle.</p>
<h3 id="features-of-the-original-dataset">
    <a href="#features-of-the-original-dataset">#</a>
    Features of the Original Dataset
</h3><p>Let&rsquo;s check the first few rows of the dataset.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">df_features</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_1.png"
	width="2351"
	height="128"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_1_hu9ae12a52bb09971cb356624aa6d450c0_37581_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_1_hu9ae12a52bb09971cb356624aa6d450c0_37581_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="1836"
		data-flex-basis="4408px"
	
></p>
<p>The author of this dataset has described the features in the dataset as follows:</p>
<ul>
<li><code>TLD</code>: TLD (Top Level Domain) is the last part of the domain name, such as .com or .edu. Phishing URLs often use TLDs that are not commonly associated with the legitimate domain, such as .link or .inf.</li>
<li><code>URLLength</code>: Phishing URLs are often longer than legitimate URLs as they contain additional digits, symbols, subdirectories, and parameters.</li>
<li><code>IsDomainIP</code>: a URL using an IP address instead of a domain name can be a red flag for users.</li>
<li><code>NoOfSubDomain</code>: Subdomain is part of URL that appears before domain name. Cybercriminals often use visual similarity techniques to trick users. They create subdomains that look like subdomain of legitimate websites.</li>
<li><code>NoOfObfuscatedChar</code>: Shows a count of obfuscated characters in URL.</li>
<li><code>IsHTTPS</code>: Indicates if the webpage is running on unsecured HTTP (hypertext transfer protocol) or secured HTTPS. A URL using the http protocol is highly likely to be a phishing URL. Most legitimate websites, especially those that require users to input sensitive information like passwords or credit card numbers, use HTTPS to protect their users’ data. If a webpage asks for sensitive information but doesn’t use HTTPS, it could be a sign that the webpage is a phishing scam.</li>
<li><strong>No. of digits, equal, qmark, amp</strong>: A large number of digits or symbols such as ‘=’, ‘?’, or ‘%’ in a URL increases the possibility of being a phishing URL.</li>
<li><code>HasFavicon</code>: Most legitimate websites have their website logo included in the favicon tag. Missing a favicon tag may indicate a phishing scam.</li>
<li><code>IsResponsive</code>: Most legitimate websites are responsive, which helps web content to be appropriately adapted across devices to give better readability and view. Fortunately, many phishing websites are not responsive, as threat actors find it challenging to ensure the responsiveness of their quickly designed websites on all major devices.</li>
<li><code>NoOfURLRedirect</code>: Phishing sites may use redirects to direct users to a different page than they were expecting. For example, the HTML code may contain JavaScript or meta tags that redirect users to a different URL. The HTML tags such as ‘http-equiv’, ‘refresh’, ‘window.location’, ‘window.location.replace’, ‘window.location-.href’, ‘http.open’ can help identify URL redirection.</li>
<li><code>HasDescription</code>: Legitimate websites provide page descriptions for each page using the ‘description’ meta name. Missing page descriptions may raise a red flag for a webpage.</li>
<li><code>NoOfPopup</code>, <code>NoOfiFrame</code>: Phishing websites may use pop-ups or iframe to distract users and capture sensitive information. These pop-ups and iframe can be detected by looking for tags ‘window.open’ and ‘iframe’ in the HTML code.</li>
<li><code>HasExternal</code> <code>FormSubmit</code>: Phishing sites often use HTML forms to collect user information. Form submitting to an external URL can be a red flag for users.</li>
<li><code>HasCopyrightInfo</code>, HasSocialNet: Most legitimate websites have copyright and their social networking information. Missing such information may indicate a phishing scam.</li>
<li><code>HasPasswordField</code>, HasSubmitButton: HTML provides a variety of form elements that allow users to input data and submit it to other URLs. For example, HTML tags such as ‘passwordfield’ or ‘submitbutton’ can be extracted to examine the HTML code of the webpage.</li>
<li><code>HasHiddenFields</code>: Phishing websites may use hidden fields to capture sensitive information without the user’s knowledge. These fields can be detected by examining the HTML code of the webpage.</li>
<li><code>Bank</code>, <code>Pay</code>, <code>Crypto</code>: Elements such as bank, pay, or crypto may indicate that the webpage is asking for sensitive financial information from the user, which may be used to siphon money. Therefore, such websites need to be analyzed for suspicious activities.</li>
<li><code>NoOfImage</code>: Threat actors can use screenshots of legitimate websites and design phishing websites to make them appear more legitimate. More images used in respectively small websites may indicate phishing websites.</li>
<li><code>NoOfJS</code>: JavaScript is a programming language that can be embedded in HTML to create interactive webpages. Phishing websites may use JavaScript to create pop-up windows or other misleading elements that trick users into revealing sensitive information. A large number of JavaScript included in a webpage can make it suspicious.</li>
<li><code>NoOfSelfRef</code>, <code>NoOfEmptyRef</code>, <code>NoOfExternalRef</code>: Hyperlinks (href) are clickable links that allow users to navigate between webpages or navigate to external webpages. Phishing websites may use hyperlinks that appear to direct to a legitimate webpage, but instead, they redirect the user to a phishing page. A large number of hyperlinks navigating to itself, navigating to empty links, or navigating to external links can be suspicious.</li>
<li><code>URLTitleMatchScore</code>: Cybercriminals often use social engineering tactics to trick users into believing a website is legitimate. They may use a URL that looks similar to a legitimate website and create a convincing webpage title reflecting the website’s content. We introduced URLTitleMatchScore to identify the discrepancy between the URL and the webpage title. A lower score can be a sign that the website is a phishing attempt because the webpage title does not match the content that is expected to be found on the website. A higher score 100 or close to 100 indicates that the website is what it claims to be. The code to calculate URLTitleMatchScore is given in Algorithm 1.</li>
<li><code>URLCharProb</code>: While most legitimate URLs look meaningful, many phishing URLs contain random alphabet, digits, and misspelled words that do not look meaningful. Often, an attacker uses the typosquatting technique to create a URL similar to a legitimate URL but with small typographical errors. To understand the pattern of each alphabet and digit in a URL, we count the occurrence of each alphabet and digit in the 10 million legitimate URLs and divide them by the total count of all alphabets and digits of 10 million legitimate URLs. Further, to compare it with the pattern of phishing URLs, we collected 7 million phishing URLs and calculated the probability of each alphabet and digit using the same method. The probability of each alphabet and digit calculated from the 10 million legitimate URLs is used to calculate the URLCharProb of a URL by combining the probability of each alphabet and digit and dividing it by the URL length. The formula to calculate the URLCharProb of each URL is given below.</li>
</ul>
<p>$$
URLCharProb = \sum_{i=0}^{n} \frac{\text{prob}(URLChar_i)}{n}
$$</p>
<ul>
<li><code>TLDLegitimateProb</code>: The top-level domain (TLD) is the last part of a domain name that indicates the purpose or origin of a URL. Phishing attackers often use TLDs that are uncommon or unrelated to the purpose of the website they are trying to spoof. Legitimate websites often use specific TLDs associated with their industry or location. We extracted all the TLDs from the top 10 million websites and counted the occurrence of each TLD. Further, we calculated the ratio of each TLD by dividing the total occurrence of that TLD by the total occurrence of all the TLDs. A higher TLDLegitimateProb of a URL may indicate a legitimate URL, and a lower TLDLegitimateProb value may help identify phishing URLs. In summary, the phishing URL dataset construction technique involves extracting and analyzing the URL, HTML, and derived features to create a comprehensive dataset for detecting phishing attacks. These features provide valuable information about the potential malicious intent of the URL.</li>
</ul>
<h3 id="data-cleaning">
    <a href="#data-cleaning">#</a>
    Data Cleaning
</h3><p>Some TLDs have port numbers such as <code>com:4000</code> which is not appropriate for the <code>TLD</code> fields. We removed the port numbers from the TLDs.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Remove any port number</span>
</span></span><span class="line"><span class="cl"><span class="n">df_features</span><span class="p">[</span><span class="s1">&#39;TLD&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_features</span><span class="p">[</span><span class="s1">&#39;TLD&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The <code>TLD</code> field appears to be extracting everything after the last dot. However, this resulted in invalid TLDs such as &lsquo;45&rsquo; because an URL could be just an IP address.</p>
<p>We fixed this by replacing any numeric TLDs with &lsquo;ip&rsquo; for the sake of our analysis. &lsquo;ip&rsquo; is not a valid TLD, but it will help us identify IP addresses.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Replace numeric TLDs with &#39;ip&#39;</span>
</span></span><span class="line"><span class="cl"><span class="n">df_features</span><span class="p">[</span><span class="s1">&#39;TLD&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_features</span><span class="p">[</span><span class="s1">&#39;TLD&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">&#39;ip&#39;</span> <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">isnumeric</span><span class="p">()</span> <span class="k">else</span> <span class="n">x</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Finally, let’s check the nulls and duplicates:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">num_nulls</span> <span class="o">=</span> <span class="n">df_urls_data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Number of null values: </span><span class="si">{</span><span class="n">num_nulls</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">num_dups</span> <span class="o">=</span> <span class="n">df_urls_data</span><span class="o">.</span><span class="n">duplicated</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Number of duplicated values: </span><span class="si">{</span><span class="n">num_dups</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Upon examining the dataset, we found no null values and duplicates. Deduplication is not needed.</p>
<p>We can proceed to the next steps!</p>
<h3 id="integrating-the-public-suffix-list-data">
    <a href="#integrating-the-public-suffix-list-data">#</a>
    Integrating the Public Suffix List Data
</h3><p>The <code>TLD</code> field currently in the dataset only contains the top-level-domains. However, we need to extract the public suffixes from the URLs. We will use the <code>publicsuffix2</code> package to extract the public suffixes from the URLs.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Install the publicsuffix2 package</span>
</span></span><span class="line"><span class="cl"><span class="c1">## Usage: https://pypi.org/project/publicsuffix2/</span>
</span></span><span class="line"><span class="cl"><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">publicsuffix2</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="what-is-the-psl">
    <a href="#what-is-the-psl">#</a>
    <strong>What is the PSL?</strong>
</h4><p>A &ldquo;public suffix&rdquo; is one under which Internet users can (or historically could) directly register names. Some examples of public suffixes are .com, .co.uk and <a class="link" href="http://pvt.k12.ma.us/"  target="_blank" rel="noopener"
    >pvt.k12.ma.us</a>. The Public Suffix List is a list of all known public suffixes.</p>
<p>It allows browsers to, for example:</p>
<ul>
<li>Avoid privacy-damaging &ldquo;supercookies&rdquo; being set for high-level domain name suffixes</li>
<li>Highlight the most important part of a domain name in the user interface</li>
<li>Accurately sort history entries by site</li>
</ul>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_2.png"
	width="770"
	height="978"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_2_hu73407acaa68cd385d2caa8c271533764_111796_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_2_hu73407acaa68cd385d2caa8c271533764_111796_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="78"
		data-flex-basis="188px"
	
></p>
<p>The Public Suffix List is an initiative of Mozilla, but is maintained as a community resource. It is available for use in any software, but was originally created to meet the needs of browser manufacturers.</p>
<ul>
<li><strong>The PSL project website</strong>: <a class="link" href="https://publicsuffix.org/"  target="_blank" rel="noopener"
    >https://publicsuffix.org</a></li>
</ul>
<p>The Public Suffix List is playing a crucial role in the operation of the Internet, yet it&rsquo;s maintained by a small team toiling in obscurity.</p>
<ul>
<li><strong>Interesting to read:</strong> <a class="link" href="https://www.m3aawg.org/blog/PublicSuffixList?trk=article-ssr-frontend-pulse_little-text-block"  target="_blank" rel="noopener"
    >The Present and Future of the Public Suffix List</a></li>
</ul>
<h4 id="what-is-etld">
    <a href="#what-is-etld">#</a>
    <strong>What is eTLD?</strong>
</h4><p>The PSL is a list of domain names that are controlled by a single organization.</p>
<p>For example, <code>co.uk</code> is a PSL domain, but <code>uk</code> is a TLD.</p>
<p>In Japan, while <code>jp</code> is a TLD, <code>co.jp</code> and <code>ne.jp</code> is an effective TLD. Japan even has city-level eTLDs like <code>tokyo.jp</code>.</p>
<p>The PSL is useful for extracting the root domain from a URL.</p>
<p>Here is a visualization of the hierarchy of some more examples:</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_3.png"
	width="1280"
	height="610"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_3_hu6c0665589841bd18d101cc4b7831826e_151317_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_3_hu6c0665589841bd18d101cc4b7831826e_151317_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="Source: Steve Jones (https://www.linkedin.com/pulse/public-suffix-list-needs-support-we-also-need-something-steve-jones)"
	
	
		class="gallery-image" 
		data-flex-grow="209"
		data-flex-basis="503px"
	
></p>
<p>Source: Steve Jones (<a class="link" href="https://www.linkedin.com/pulse/public-suffix-list-needs-support-we-also-need-something-steve-jones"  target="_blank" rel="noopener"
    >https://www.linkedin.com/pulse/public-suffix-list-needs-support-we-also-need-something-steve-jones</a>)</p>
<h4 id="eda-implications">
    <a href="#eda-implications">#</a>
    <strong>EDA implications</strong>
</h4><p>In the EDA section, we are also going to explore the pricing of domain names. The PSL is useful for this analysis because the prices are different for second-level domains (SLDs) and top-level domains (TLDs) in some cases. For example, the price of <code>.co.uk</code> may be different from <code>.uk</code>.</p>
<h4 id="integrating-the-psl-data">
    <a href="#integrating-the-psl-data">#</a>
    Integrating the PSL Data
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">psl</span> <span class="o">=</span> <span class="n">PublicSuffixList</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Extract the domain and second level domain (SLD)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">extract_domain_and_sld</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">parsed_url</span> <span class="o">=</span> <span class="n">urlparse</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">domain</span> <span class="o">=</span> <span class="n">parsed_url</span><span class="o">.</span><span class="n">netloc</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="ow">not</span> <span class="n">domain</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">domain</span> <span class="o">=</span> <span class="n">url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="c1">#passed directly as domain names</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Strip away port numbers and username/password in URL</span>
</span></span><span class="line"><span class="cl">    <span class="n">domain</span> <span class="o">=</span> <span class="n">domain</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;@&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Replace any backslashes</span>
</span></span><span class="line"><span class="cl">    <span class="n">domain</span> <span class="o">=</span> <span class="n">domain</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;/&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Use publicsuffix2 to extract the second level domain (SLD)</span>
</span></span><span class="line"><span class="cl">    <span class="n">tld</span> <span class="o">=</span> <span class="n">get_tld</span><span class="p">(</span><span class="n">domain</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;domain&#39;</span><span class="p">:</span> <span class="n">domain</span><span class="p">,</span> <span class="s1">&#39;tld&#39;</span><span class="p">:</span> <span class="n">tld</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="c1">## Extract the eTLD</span>
</span></span><span class="line"><span class="cl"><span class="n">df_features</span><span class="p">[</span><span class="s1">&#39;PublicSuffix&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_features</span><span class="p">[</span><span class="s1">&#39;URL&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">extract_domain_and_sld</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="s1">&#39;tld&#39;</span><span class="p">])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Make sure the public suffixes have been extracted properly:</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_4.png"
	width="409"
	height="245"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_4_huc6b25119b3b85bbafac53d9f588aa231_22908_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_4_huc6b25119b3b85bbafac53d9f588aa231_22908_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="166"
		data-flex-basis="400px"
	
></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## List the unique values of PublicSuffix</span>
</span></span><span class="line"><span class="cl"><span class="n">unique_ps</span> <span class="o">=</span> <span class="n">df_features</span><span class="p">[</span><span class="s1">&#39;PublicSuffix&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Unique PublicSuffix: </span><span class="si">{</span><span class="n">unique_ps</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Check for null values</span>
</span></span><span class="line"><span class="cl"><span class="n">num_nulls_ps</span> <span class="o">=</span> <span class="n">df_features</span><span class="p">[</span><span class="s1">&#39;PublicSuffix&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Number of null in PublicSuffix: </span><span class="si">{</span><span class="n">num_nulls_ps</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Output: Number of null in PublicSuffix: 0 </span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="integrating-the-domain-pricing-data">
    <a href="#integrating-the-domain-pricing-data">#</a>
    Integrating the Domain Pricing Data
</h3><h4 id="background-on-pricing-of-domain-names">
    <a href="#background-on-pricing-of-domain-names">#</a>
    Background on Pricing of Domain Names
</h4><p><strong>How domains are acquired?</strong></p>
<p>The domains are acquired through domain registrars. The domain registrars are mostly accredited by the registries. The domain registrars are responsible for selling domain names to the public.</p>
<p>Note - difference between registrar and registry: The registry is responsible for managing the top-level domain (TLD) and the registrar is responsible for selling the domain names to the public.</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_5.png"
	width="1268"
	height="660"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_5_hu5d91c997d995eb95c0d54281cd5bc155_71410_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_5_hu5d91c997d995eb95c0d54281cd5bc155_71410_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="Source: Cloudflare (https://www.cloudflare.com/learning/dns/glossary/what-is-a-domain-name-registrar/)"
	
	
		class="gallery-image" 
		data-flex-grow="192"
		data-flex-basis="461px"
	
></p>
<p>Source: Cloudflare (<a class="link" href="https://www.cloudflare.com/learning/dns/glossary/what-is-a-domain-name-registrar/"  target="_blank" rel="noopener"
    >https://www.cloudflare.com/learning/dns/glossary/what-is-a-domain-name-registrar/</a>)</p>
<p><strong>So, at what price are domains sold?</strong></p>
<p>The domain prices are set by the domain registrars. The prices vary depending on the domain extension. For example, &lsquo;.com&rsquo; domains are generally more expensive than &lsquo;.xyz&rsquo; domains. So, that makes &lsquo;.xyz&rsquo; more likely to be used by phishers.</p>
<h4 id="acquire-pricing-data-of-domain-names">
    <a href="#acquire-pricing-data-of-domain-names">#</a>
    Acquire Pricing Data of Domain Names
</h4><p>Since different domain registrar charges prices differently even for the same domain suffix. For example, GoDaddy sells <code>.com</code> more expensive than Namecheap.</p>
<p>We assume that the phisers want to save money and they will choose the cheapest domain registrar to buy the domain. So, we will use the cheapest price of the domain suffix as the price of the domain suffix available in the market.</p>
<h4 id="acquiring-the-domain-market-data">
    <a href="#acquiring-the-domain-market-data">#</a>
    Acquiring the Domain Market Data
</h4><p>One of the best sources for domain pricing data is the domain registrars themselves. We will use the <a class="link" href="http://tld-list.com/"  target="_blank" rel="noopener"
    >tld-list.com</a> platform, which provides domain pricing data for various domain registrars.</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_6.png"
	width="1618"
	height="1227"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_6_hub821399d32489995430e4022f67d8473_325243_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_6_hub821399d32489995430e4022f67d8473_325243_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="Source: TLD-list (https://tld-list.com)"
	
	
		class="gallery-image" 
		data-flex-grow="131"
		data-flex-basis="316px"
	
></p>
<p>Source: TLD-list (<a class="link" href="https://tld-list.com/"  target="_blank" rel="noopener"
    >https://tld-list.com</a>)</p>
<p>The data has been dumped from the <a class="link" href="http://tld-list.com/"  target="_blank" rel="noopener"
    >tld-list.com</a> platform and stored in a Cloudflare R2 storage bucket. We will download the data and load it into a dataframe.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Load the TLD pricing data</span>
</span></span><span class="line"><span class="cl"><span class="n">df_tld_pricing</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;tld-pricing.csv&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df_tld_pricing</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_7.png"
	width="631"
	height="200"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_7_hue5252883a42058df61afdcb9ec31d5ab_36963_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_7_hue5252883a42058df61afdcb9ec31d5ab_36963_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="315"
		data-flex-basis="757px"
	
></p>
<p>Obviously, we need to perform some data cleaning work.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## remove anything before &#39;$&#39; for all cols and all rows</span>
</span></span><span class="line"><span class="cl"><span class="n">df_tld_pricing</span><span class="p">[</span><span class="s1">&#39;new&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_tld_pricing</span><span class="p">[</span><span class="s1">&#39;new&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;(\d+\.\d+)&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df_tld_pricing</span> <span class="o">=</span> <span class="n">df_tld_pricing</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;renew&#39;</span><span class="p">,</span> <span class="s1">&#39;transfer&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">df_tld_pricing</span> <span class="o">=</span> <span class="n">df_tld_pricing</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## get rid of the first dot in tld, if exists</span>
</span></span><span class="line"><span class="cl"><span class="n">df_tld_pricing</span><span class="p">[</span><span class="s1">&#39;tld&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_tld_pricing</span><span class="p">[</span><span class="s1">&#39;tld&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## df_tld_pricing.head()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## rename columns &#39;new&#39;: &#39;DomainPrice&#39;, &#39;tld&#39;: &#39;PublicSuffix&#39;</span>
</span></span><span class="line"><span class="cl"><span class="n">df_tld_pricing</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;PublicSuffix&#39;</span><span class="p">,</span> <span class="s1">&#39;DomainPrice&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## drop any rows missing &#39;new&#39; price</span>
</span></span><span class="line"><span class="cl"><span class="n">df_tld_pricing</span> <span class="o">=</span> <span class="n">df_tld_pricing</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;DomainPrice&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">df_tld_pricing</span> <span class="o">=</span> <span class="n">df_tld_pricing</span><span class="p">[</span><span class="n">df_tld_pricing</span><span class="p">[</span><span class="s1">&#39;DomainPrice&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># keep only &gt; 0 prices</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_8.png"
	width="347"
	height="246"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_8_huafe032b8cfc0471d46acd86db4f9efcd_12056_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_8_huafe032b8cfc0471d46acd86db4f9efcd_12056_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="141"
		data-flex-basis="338px"
	
></p>
<p>There are certain suffixes of which a domain price is not available due to many reasons. We impute these values with the median domain price, which is $15.60, a reasonable price in the domain name industry.</p>
<p>Note: Not all TLDs have pricing data. We will fill the missing values with the <code>median_domain_price</code> of the TLDs. For TLDs missing pricing data, we have to use the median price of the TLDs. Some registry prices are crazy high, and we don&rsquo;t want to skew the data by using a mean.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">median_domain_price</span> <span class="o">=</span> <span class="n">df_tld_pricing</span><span class="p">[</span><span class="s1">&#39;DomainPrice&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="c1">## Median Domain Price: $15.60</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="convert-the-idn-domains-punycode">
    <a href="#convert-the-idn-domains-punycode">#</a>
    Convert the IDN Domains (Punycode)
</h4><p>You may have noticed that in the &ldquo;Fix TLD Data&rdquo; step, some suffix looks weird. For example, <code>xn--90ais</code>. This is because they are in the Internationalized Domain Name (IDN) format. We will convert them to the Unicode format.</p>
<p>IDN domains are internationalized domain names that uses non-ASCII characters.</p>
<p>Learn more about IDN: <a class="link" href="https://www.icann.org/resources/pages/idn-2012-02-25-en"  target="_blank" rel="noopener"
    >https://www.icann.org/resources/pages/idn-2012-02-25-en</a></p>
<p>For example, the IDN domain <code>example.公司</code> will be converted to the punycode domain <code>example.xn--55qx5d</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">convert_ascii_to_punycode</span><span class="p">(</span><span class="n">ascii_str</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">ascii_str</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;idna&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">example_idn</span> <span class="o">=</span> <span class="s1">&#39;公司&#39;</span>
</span></span><span class="line"><span class="cl"><span class="n">example_idn_int</span> <span class="o">=</span> <span class="n">convert_ascii_to_punycode</span><span class="p">(</span><span class="n">example_idn</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Example IDN: </span><span class="si">{</span><span class="n">example_idn</span><span class="si">}</span><span class="s2"> =&gt; </span><span class="si">{</span><span class="n">example_idn_int</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Example IDN: 公司 =&gt; xn--55qx5d</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="join-the-tld-pricing-data-with-df_features">
    <a href="#join-the-tld-pricing-data-with-df_features">#</a>
    Join the TLD Pricing Data with <code>df_features</code>
</h4><p>Now we have acquired all market prices for the TLDs. We will join the pricing data with the <code>df_features</code> dataframe.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">df_features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df_features</span><span class="p">,</span> <span class="n">df_tld_pricing</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;PublicSuffix&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df_features</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_9.png"
	width="2471"
	height="323"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_9_hu5deae75a6502cb3f52be61b9cc1ec6e3_71865_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_9_hu5deae75a6502cb3f52be61b9cc1ec6e3_71865_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="765"
		data-flex-basis="1836px"
	
></p>
<h3 id="remove-unnecessary-labels">
    <a href="#remove-unnecessary-labels">#</a>
    Remove Unnecessary Labels
</h3><p>We will remove the columns that are not needed for the analysis. This includes the <code>Title</code>, <code>URL</code>, <code>Domain</code>, and <code>FILENAME</code> columns.</p>
<p>NOTE: These columns are not needed for the analysis but could be useful for other types of analysis such as NLP or extracting additional features if needed.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">df_features</span> <span class="o">=</span> <span class="n">df_features</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Title&#39;</span><span class="p">,</span> <span class="s1">&#39;URL&#39;</span><span class="p">,</span> <span class="s1">&#39;Domain&#39;</span><span class="p">,</span> <span class="s1">&#39;FILENAME&#39;</span><span class="p">])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="understanding-features-input-data">
    <a href="#understanding-features-input-data">#</a>
    Understanding Features (Input) Data
</h3><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## sort the columns in alphabetic order</span>
</span></span><span class="line"><span class="cl"><span class="n">df_features</span> <span class="o">=</span> <span class="n">df_features</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">df_features</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">df_features</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="c1"># number of unique values</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Output:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">Bank                               2
</span></span><span class="line"><span class="cl">CharContinuationRate             898
</span></span><span class="line"><span class="cl">Crypto                             2
</span></span><span class="line"><span class="cl">DegitRatioInURL                  575
</span></span><span class="line"><span class="cl">DomainLength                     101
</span></span><span class="line"><span class="cl">DomainPrice                      406
</span></span><span class="line"><span class="cl">DomainTitleMatchScore            152
</span></span><span class="line"><span class="cl">HasCopyrightInfo                   2
</span></span><span class="line"><span class="cl">HasDescription                     2
</span></span><span class="line"><span class="cl">HasExternalFormSubmit              2
</span></span><span class="line"><span class="cl">HasFavicon                         2
</span></span><span class="line"><span class="cl">HasHiddenFields                    2
</span></span><span class="line"><span class="cl">HasObfuscation                     2
</span></span><span class="line"><span class="cl">HasPasswordField                   2
</span></span><span class="line"><span class="cl">HasSocialNet                       2
</span></span><span class="line"><span class="cl">HasSubmitButton                    2
</span></span><span class="line"><span class="cl">HasTitle                           2
</span></span><span class="line"><span class="cl">IsDomainIP                         2
</span></span><span class="line"><span class="cl">IsHTTPS                            2
</span></span><span class="line"><span class="cl">IsResponsive                       2
</span></span><span class="line"><span class="cl">LargestLineLength              26181
</span></span><span class="line"><span class="cl">LetterRatioInURL                 709
</span></span><span class="line"><span class="cl">LineOfCode                     10738
</span></span><span class="line"><span class="cl">NoOfAmpersandInURL                31
</span></span><span class="line"><span class="cl">NoOfCSS                          209
</span></span><span class="line"><span class="cl">NoOfDegitsInURL                  182
</span></span><span class="line"><span class="cl">NoOfEmptyRef                     296
</span></span><span class="line"><span class="cl">NoOfEqualsInURL                   25
</span></span><span class="line"><span class="cl">NoOfExternalRef                 1191
</span></span><span class="line"><span class="cl">NoOfImage                        992
</span></span><span class="line"><span class="cl">NoOfJS                           253
</span></span><span class="line"><span class="cl">NoOfLettersInURL                 421
</span></span><span class="line"><span class="cl">NoOfObfuscatedChar                20
</span></span><span class="line"><span class="cl">NoOfOtherSpecialCharsInURL        74
</span></span><span class="line"><span class="cl">NoOfPopup                        115
</span></span><span class="line"><span class="cl">NoOfQMarkInURL                     5
</span></span><span class="line"><span class="cl">NoOfSelfRedirect                   2
</span></span><span class="line"><span class="cl">NoOfSelfRef                     1374
</span></span><span class="line"><span class="cl">NoOfSubDomain                     10
</span></span><span class="line"><span class="cl">NoOfURLRedirect                    2
</span></span><span class="line"><span class="cl">NoOfiFrame                       119
</span></span><span class="line"><span class="cl">ObfuscationRatio                 146
</span></span><span class="line"><span class="cl">Pay                                2
</span></span><span class="line"><span class="cl">PublicSuffix                    2100
</span></span><span class="line"><span class="cl">Robots                             2
</span></span><span class="line"><span class="cl">SpacialCharRatioInURL            240
</span></span><span class="line"><span class="cl">TLD                              570
</span></span><span class="line"><span class="cl">TLDLegitimateProb                465
</span></span><span class="line"><span class="cl">TLDLength                         12
</span></span><span class="line"><span class="cl">URLCharProb                   227421
</span></span><span class="line"><span class="cl">URLLength                        482
</span></span><span class="line"><span class="cl">URLSimilarityIndex             36360
</span></span><span class="line"><span class="cl">URLTitleMatchScore               497
</span></span><span class="line"><span class="cl">dtype: int64
</span></span></code></pre></td></tr></table>
</div>
</div><p>Note that although many fields appear numerical, they could actually be categorical, especially if some fields have only 2 unique values.</p>
<p>Additionally, labels with names beginning with &ldquo;Has&rdquo; or &ldquo;Is&rdquo; are likely to be categorical data.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">df_features</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Number of total features: </span><span class="si">{</span><span class="n">df_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">, before splitting&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Number of total features: 53, before splitting.</p>
<h4 id="split-numerical-and-categorical-input-features">
    <a href="#split-numerical-and-categorical-input-features">#</a>
    Split numerical and categorical input features
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## split non-numeric and numeric columns</span>
</span></span><span class="line"><span class="cl"><span class="n">df_features_numerical</span> <span class="o">=</span> <span class="n">df_features</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">df_features_categorical</span> <span class="o">=</span> <span class="n">df_features</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">exclude</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## categorize the columns with field name starting with &#39;Has&#39; and &#39;Is&#39; as categorical</span>
</span></span><span class="line"><span class="cl"><span class="n">has_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df_features</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">col</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;Has&#39;</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl"><span class="n">is_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df_features</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">col</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;Is&#39;</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">df_features_categorical</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_features_categorical</span><span class="p">,</span> <span class="n">df_features</span><span class="p">[</span><span class="n">has_columns</span><span class="p">],</span> <span class="n">df_features</span><span class="p">[</span><span class="n">is_columns</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df_features_numerical</span> <span class="o">=</span> <span class="n">df_features_numerical</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">has_columns</span> <span class="o">+</span> <span class="n">is_columns</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">df_features_numerical</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span> <span class="c1"># to examine if they are indeed numerical</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Let’s move while observing the features to categorical if they only have 0 and 1 values.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## move the features to categorical if they only have 0 and 1 values</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df_features_numerical</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">df_features_numerical</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="n">df_features_numerical</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span> <span class="o">==</span> <span class="p">{</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">}:</span>
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Moving </span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2"> to categorical&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">df_features_categorical</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_features_numerical</span><span class="p">[</span><span class="n">col</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">df_features_numerical</span> <span class="o">=</span> <span class="n">df_features_numerical</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">col</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Output (checked the values to make sure they are indeed categorical):</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">Moving Bank to categorical
</span></span><span class="line"><span class="cl">Moving Crypto to categorical
</span></span><span class="line"><span class="cl">Moving NoOfSelfRedirect to categorical
</span></span><span class="line"><span class="cl">Moving NoOfURLRedirect to categorical
</span></span><span class="line"><span class="cl">Moving Pay to categorical
</span></span><span class="line"><span class="cl">Moving Robots to categorical
</span></span></code></pre></td></tr></table>
</div>
</div><p>After splitting the data:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Number of numerical features: </span><span class="si">{</span><span class="n">df_features_numerical</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Number of categorical features: </span><span class="si">{</span><span class="n">df_features_categorical</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Total number of features: </span><span class="si">{</span><span class="n">df_features_numerical</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">df_features_categorical</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>We have identified:</p>
<ul>
<li>32 numerical features</li>
<li>21 categorical features</li>
<li>A total of 53 features</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">df_features_numerical</span><span class="o">.</span><span class="n">dtypes</span>
</span></span><span class="line"><span class="cl"><span class="n">df_features_numerical</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="c1"># number of unique values</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">df_features_categorical</span><span class="o">.</span><span class="n">dtypes</span>
</span></span><span class="line"><span class="cl"><span class="n">df_features_categorical</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="c1"># number of unique values</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">## Field names of categorical data:
</span></span><span class="line"><span class="cl">df_features_categorical.columns
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Index([&#39;PublicSuffix&#39;, &#39;TLD&#39;, &#39;HasCopyrightInfo&#39;, &#39;HasDescription&#39;,
</span></span><span class="line"><span class="cl">       &#39;HasExternalFormSubmit&#39;, &#39;HasFavicon&#39;, &#39;HasHiddenFields&#39;,
</span></span><span class="line"><span class="cl">       &#39;HasObfuscation&#39;, &#39;HasPasswordField&#39;, &#39;HasSocialNet&#39;, &#39;HasSubmitButton&#39;,
</span></span><span class="line"><span class="cl">       &#39;HasTitle&#39;, &#39;IsDomainIP&#39;, &#39;IsHTTPS&#39;, &#39;IsResponsive&#39;, &#39;Bank&#39;, &#39;Crypto&#39;,
</span></span><span class="line"><span class="cl">       &#39;NoOfSelfRedirect&#39;, &#39;NoOfURLRedirect&#39;, &#39;Pay&#39;, &#39;Robots&#39;],
</span></span><span class="line"><span class="cl">      dtype=&#39;object&#39;)
</span></span><span class="line"><span class="cl">      
</span></span><span class="line"><span class="cl">## Field names of numerical data:
</span></span><span class="line"><span class="cl">df_features_numerical.columns
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Index([&#39;CharContinuationRate&#39;, &#39;DegitRatioInURL&#39;, &#39;DomainLength&#39;,
</span></span><span class="line"><span class="cl">       &#39;DomainPrice&#39;, &#39;DomainTitleMatchScore&#39;, &#39;LargestLineLength&#39;,
</span></span><span class="line"><span class="cl">       &#39;LetterRatioInURL&#39;, &#39;LineOfCode&#39;, &#39;NoOfAmpersandInURL&#39;, &#39;NoOfCSS&#39;,
</span></span><span class="line"><span class="cl">       &#39;NoOfDegitsInURL&#39;, &#39;NoOfEmptyRef&#39;, &#39;NoOfEqualsInURL&#39;, &#39;NoOfExternalRef&#39;,
</span></span><span class="line"><span class="cl">       &#39;NoOfImage&#39;, &#39;NoOfJS&#39;, &#39;NoOfLettersInURL&#39;, &#39;NoOfObfuscatedChar&#39;,
</span></span><span class="line"><span class="cl">       &#39;NoOfOtherSpecialCharsInURL&#39;, &#39;NoOfPopup&#39;, &#39;NoOfQMarkInURL&#39;,
</span></span><span class="line"><span class="cl">       &#39;NoOfSelfRef&#39;, &#39;NoOfSubDomain&#39;, &#39;NoOfiFrame&#39;, &#39;ObfuscationRatio&#39;,
</span></span><span class="line"><span class="cl">       &#39;SpacialCharRatioInURL&#39;, &#39;TLDLegitimateProb&#39;, &#39;TLDLength&#39;,
</span></span><span class="line"><span class="cl">       &#39;URLCharProb&#39;, &#39;URLLength&#39;, &#39;URLSimilarityIndex&#39;, &#39;URLTitleMatchScore&#39;],
</span></span><span class="line"><span class="cl">      dtype=&#39;object&#39;)
</span></span></code></pre></td></tr></table>
</div>
</div><p>We will proceed to analyze the data following the split.</p>
<h3 id="one-hot-encoding">
    <a href="#one-hot-encoding">#</a>
    <strong>One Hot Encoding</strong>
</h3><p>In machine learning, most algorithms require input data in a numerical format because they perform calculations with these numbers during the learning process. Categorical data, such as labels or categories, inherently lack a numerical representation and thus cannot be directly processed by these algorithms.</p>
<p>Converting these categorical variables into a numerical format allows machine learning algorithms to efficiently include these features in computations for tasks like classification or regression.</p>
<p>Let’s now convert our categorical variables from two <code>DataFrame</code> subsets (<strong><code>df_features_categorical</code></strong> and <strong><code>df_features</code></strong>) into numerical format by applying one-hot encoding.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## One hot encode categorical labels</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">do_one_hot_encoding</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">df_features_categorical_encoded</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">df_features_categorical</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">categorical_columns_lst</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">df_features_encoded</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">df_features</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">categorical_columns_lst</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="completing-the-preprocessing-steps">
    <a href="#completing-the-preprocessing-steps">#</a>
    Completing the Preprocessing Steps
</h3><p>We have successfully completed the data preprocessing steps and now have the following dataframes ready for our next steps:</p>
<ul>
<li><code>df_urls_data</code> contains the original dataset, including both features and target.</li>
<li><code>df_features</code> contains the features only.</li>
<li><code>df_features_raw</code> contains the raw features such as the URL, Title, and Domain.</li>
<li><code>df_features_encoded</code> contains the encoded features.</li>
<li><code>df_target</code> contains the target only.</li>
<li><code>df_features_numerical</code> contains the numerical features only.</li>
<li><code>df_features_categorical</code> contains the categorical features only.</li>
<li><code>df_features_categorical_encoded</code> contains the encoded categorical features</li>
</ul>
<hr>
<h2 id="exploratory-data-analysis">
    <a href="#exploratory-data-analysis">#</a>
    <strong>Exploratory Data Analysis</strong>
</h2><h3 id="install-dependencies">
    <a href="#install-dependencies">#</a>
    Install Dependencies
</h3><p>First, let&rsquo;s install the required dependencies and then import them.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">pandas</span> <span class="n">numpy</span> <span class="n">matplotlib</span> <span class="n">seaborn</span> <span class="n">scikit</span><span class="o">-</span><span class="n">learn</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## visualization of missing values</span>
</span></span><span class="line"><span class="cl"><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">missingno</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## plotly</span>
</span></span><span class="line"><span class="cl"><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">plotly</span>
</span></span><span class="line"><span class="cl"><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="s2">&#34;nbformat&gt;=4.2.0&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## country codes conversion</span>
</span></span><span class="line"><span class="cl"><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">pycountry</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## scipy</span>
</span></span><span class="line"><span class="cl"><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">scipy</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## import packages</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">missingno</span> <span class="k">as</span> <span class="nn">msno</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">chi2_contingency</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">ttest_ind</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="nn">px</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Check the first 5 rows to get a feel of the data</span>
</span></span><span class="line"><span class="cl"><span class="n">df_urls_data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_10.png"
	width="2338"
	height="220"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_10_huf05d71cc1c3b37aebb94434e50403c56_67297_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_10_huf05d71cc1c3b37aebb94434e50403c56_67297_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="1062"
		data-flex-basis="2550px"
	
></p>
<p>Let&rsquo;s also check the shape of the dataframes. Make sure they are loaded correctly from the preprocessing notebook.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Check the shape of categorical data</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Shape of df_features_categorical: </span><span class="si">{</span><span class="n">df_features_categorical</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Data types of df_features:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df_features_categorical</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Check the shape of numerical data</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Shape of df_features_numerical: </span><span class="si">{</span><span class="n">df_features_numerical</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Data types of df_features_numerical:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df_features_numerical</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">Shape of df_features_categorical: (235795, 21)
</span></span><span class="line"><span class="cl">Data types of df_features:
</span></span><span class="line"><span class="cl">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
</span></span><span class="line"><span class="cl">RangeIndex: 235795 entries, 0 to 235794
</span></span><span class="line"><span class="cl">Data columns (total 21 columns):
</span></span><span class="line"><span class="cl"> #   Column                 Non-Null Count   Dtype 
</span></span><span class="line"><span class="cl">---  ------                 --------------   ----- 
</span></span><span class="line"><span class="cl"> 0   PublicSuffix           235795 non-null  object
</span></span><span class="line"><span class="cl"> 1   TLD                    235795 non-null  object
</span></span><span class="line"><span class="cl"> 2   HasCopyrightInfo       235795 non-null  int64 
</span></span><span class="line"><span class="cl"> 3   HasDescription         235795 non-null  int64 
</span></span><span class="line"><span class="cl"> 4   HasExternalFormSubmit  235795 non-null  int64 
</span></span><span class="line"><span class="cl"> 5   HasFavicon             235795 non-null  int64 
</span></span><span class="line"><span class="cl"> 6   HasHiddenFields        235795 non-null  int64 
</span></span><span class="line"><span class="cl"> 7   HasObfuscation         235795 non-null  int64 
</span></span><span class="line"><span class="cl"> 8   HasPasswordField       235795 non-null  int64 
</span></span><span class="line"><span class="cl"> 9   HasSocialNet           235795 non-null  int64 
</span></span><span class="line"><span class="cl"> 10  HasSubmitButton        235795 non-null  int64 
</span></span><span class="line"><span class="cl"> 11  HasTitle               235795 non-null  int64 
</span></span><span class="line"><span class="cl"> 12  IsDomainIP             235795 non-null  int64 
</span></span><span class="line"><span class="cl"> 13  IsHTTPS                235795 non-null  int64 
</span></span><span class="line"><span class="cl"> 14  IsResponsive           235795 non-null  int64 
</span></span><span class="line"><span class="cl"> 15  Bank                   235795 non-null  int64 
</span></span><span class="line"><span class="cl"> 16  Crypto                 235795 non-null  int64 
</span></span><span class="line"><span class="cl"> 17  NoOfSelfRedirect       235795 non-null  int64 
</span></span><span class="line"><span class="cl"> 18  NoOfURLRedirect        235795 non-null  int64 
</span></span><span class="line"><span class="cl"> 19  Pay                    235795 non-null  int64 
</span></span><span class="line"><span class="cl"> 20  Robots                 235795 non-null  int64 
</span></span><span class="line"><span class="cl">dtypes: int64(19), object(2)
</span></span><span class="line"><span class="cl">memory usage: 37.8+ MB
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Shape of df_features_numerical: (235795, 32)
</span></span><span class="line"><span class="cl">Data types of df_features_numerical:
</span></span><span class="line"><span class="cl">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
</span></span><span class="line"><span class="cl">RangeIndex: 235795 entries, 0 to 235794
</span></span><span class="line"><span class="cl">Data columns (total 32 columns):
</span></span><span class="line"><span class="cl"> #   Column                      Non-Null Count   Dtype  
</span></span><span class="line"><span class="cl">---  ------                      --------------   -----  
</span></span><span class="line"><span class="cl"> 0   CharContinuationRate        235795 non-null  float64
</span></span><span class="line"><span class="cl"> 1   DegitRatioInURL             235795 non-null  float64
</span></span><span class="line"><span class="cl"> 2   DomainLength                235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 3   DomainPrice                 235795 non-null  float64
</span></span><span class="line"><span class="cl"> 4   DomainTitleMatchScore       235795 non-null  float64
</span></span><span class="line"><span class="cl"> 5   LargestLineLength           235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 6   LetterRatioInURL            235795 non-null  float64
</span></span><span class="line"><span class="cl"> 7   LineOfCode                  235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 8   NoOfAmpersandInURL          235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 9   NoOfCSS                     235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 10  NoOfDegitsInURL             235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 11  NoOfEmptyRef                235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 12  NoOfEqualsInURL             235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 13  NoOfExternalRef             235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 14  NoOfImage                   235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 15  NoOfJS                      235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 16  NoOfLettersInURL            235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 17  NoOfObfuscatedChar          235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 18  NoOfOtherSpecialCharsInURL  235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 19  NoOfPopup                   235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 20  NoOfQMarkInURL              235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 21  NoOfSelfRef                 235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 22  NoOfSubDomain               235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 23  NoOfiFrame                  235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 24  ObfuscationRatio            235795 non-null  float64
</span></span><span class="line"><span class="cl"> 25  SpacialCharRatioInURL       235795 non-null  float64
</span></span><span class="line"><span class="cl"> 26  TLDLegitimateProb           235795 non-null  float64
</span></span><span class="line"><span class="cl"> 27  TLDLength                   235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 28  URLCharProb                 235795 non-null  float64
</span></span><span class="line"><span class="cl"> 29  URLLength                   235795 non-null  int64  
</span></span><span class="line"><span class="cl"> 30  URLSimilarityIndex          235795 non-null  float64
</span></span><span class="line"><span class="cl"> 31  URLTitleMatchScore          235795 non-null  float64
</span></span><span class="line"><span class="cl">dtypes: float64(11), int64(21)
</span></span><span class="line"><span class="cl">memory usage: 57.6 MB
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Visualize missing values as a matrix</span>
</span></span><span class="line"><span class="cl"><span class="n">msno</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">df_features_categorical</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_11.png"
	width="2097"
	height="1021"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_11_hu702204b5ad0e0d6b2357f9ba0dd6ec1f_132149_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_11_hu702204b5ad0e0d6b2357f9ba0dd6ec1f_132149_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="205"
		data-flex-basis="492px"
	
></p>
<p>It appears that there are no missing values in the dataset. This is good news!</p>
<h3 id="understanding-target-data">
    <a href="#understanding-target-data">#</a>
    Understanding Target Data
</h3><h4 id="number-of-phishing-vs-legitimate-data">
    <a href="#number-of-phishing-vs-legitimate-data">#</a>
    Number of phishing vs legitimate data
</h4><p>The target label of this dataset is binary, where <code>0</code> represents phishing and <code>1</code> represents legitimate.</p>
<p>So, the next question come to my mind: <strong>How balanced is the target of our dataset?</strong></p>
<p>Check how many phishing and non-phishing data in the dataset.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">non_phishing_counts</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">df_target</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">phishing_counts</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">df_target</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## let&#39;s count the number of phishing and non-phishing URLs</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Non-phishing counts: </span><span class="si">{</span><span class="n">non_phishing_counts</span><span class="si">}</span><span class="s2"> &#34;</span>
</span></span><span class="line"><span class="cl">      <span class="sa">f</span><span class="s2">&#34;(Percentage: </span><span class="si">{</span><span class="n">non_phishing_counts</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df_target</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%)&#34;</span><span class="p">)</span> <span class="c1">#get percentage</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Phishing counts: </span><span class="si">{</span><span class="n">phishing_counts</span><span class="si">}</span><span class="s2"> &#34;</span>
</span></span><span class="line"><span class="cl">      <span class="sa">f</span><span class="s2">&#34;(Percentage: </span><span class="si">{</span><span class="n">phishing_counts</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df_target</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%)&#34;</span><span class="p">)</span> <span class="c1">#get percentage</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>We obtained:</p>
<ul>
<li>Non-phishing counts: 134850 (Percentage: 57.19%)</li>
<li>Phishing counts: 100945 (Percentage: 42.81%)</li>
</ul>
<p>Let&rsquo;s also visualize the distribution of the target label.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Plot for phishing</span>
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;label&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span><span class="o">=</span><span class="n">df_target</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;label&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="n">palette</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Count of Phishing vs Non-Phishing URLs&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Count&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">ticks</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">            <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Phishing&#39;</span><span class="p">,</span><span class="s1">&#39;Non-Phishing&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_12.png"
	width="566"
	height="393"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_12_hua463ae7296fd052d3cbe20e712c6736d_24981_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_12_hua463ae7296fd052d3cbe20e712c6736d_24981_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="144"
		data-flex-basis="345px"
	
></p>
<p>Based on the distribution, we can see the target label is not too imbalanced. We can proceed with the dataset as it is.</p>
<h3 id="understanding-numerical-features">
    <a href="#understanding-numerical-features">#</a>
    Understanding Numerical Features
</h3><h4 id="correlation-matrix">
    <a href="#correlation-matrix">#</a>
    Correlation Matrix
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## combine df_features_numerical and df_target</span>
</span></span><span class="line"><span class="cl"><span class="n">df_urls_numerical</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_features_numerical</span><span class="p">,</span> <span class="n">df_target</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">columns</span> <span class="o">=</span> <span class="n">df_urls_numerical</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">corr_mat</span> <span class="o">=</span> <span class="n">df_urls_numerical</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">corr_mat</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;RdBu&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">center</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">fmt</span><span class="o">=</span><span class="s2">&#34;.1f&#34;</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_13.png"
	width="4748"
	height="5167"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_13_hu4a35c59d1453e2283420b5087be14aca_1419125_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_13_hu4a35c59d1453e2283420b5087be14aca_1419125_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="91"
		data-flex-basis="220px"
	
></p>
<p>Identify the feature pairs that have high correlation (threshold = 0.8):</p>
<ul>
<li>NoOfEqualsInURL and NoOfDegitsInURL has high correlation = 0.80602442162387</li>
<li>URLLength and NoOfDegitsInURL has high correlation = 0.8358093990245989</li>
<li>URLLength and NoOfLettersInURL has high correlation = 0.9560469859044239</li>
<li>URLTitleMatchScore and DomainTitleMatchScore has high correlation = 0.9610084343550412</li>
<li>label and URLSimilarityIndex has high correlation = 0.8603580349950561</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Print features having high correlation with the target &#39;label&#39;</span>
</span></span><span class="line"><span class="cl"><span class="n">corr_target</span> <span class="o">=</span> <span class="n">corr_mat</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">corr_target_top_5</span> <span class="o">=</span> <span class="n">corr_target</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">corr_target_top_5</span> <span class="o">=</span> <span class="n">corr_target_top_5</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="c1"># remove label itself</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">corr_target_top_5</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">URLSimilarityIndex</span>       <span class="mf">0.860358</span>
</span></span><span class="line"><span class="cl"><span class="n">DomainTitleMatchScore</span>    <span class="mf">0.584905</span>
</span></span><span class="line"><span class="cl"><span class="n">URLTitleMatchScore</span>       <span class="mf">0.539419</span>
</span></span><span class="line"><span class="cl"><span class="n">URLCharProb</span>              <span class="mf">0.469749</span>
</span></span><span class="line"><span class="cl"><span class="n">CharContinuationRate</span>     <span class="mf">0.467735</span>
</span></span><span class="line"><span class="cl"><span class="n">Name</span><span class="p">:</span> <span class="n">label</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">float64</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="violin-plots">
    <a href="#violin-plots">#</a>
    <strong>Violin Plots</strong>
</h4><p>Plot violin plots for the numerical features with the target label <code>Phishing</code>.</p>
<p>Recall <code>0</code> represents phishing and <code>1</code> represents legitimate.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">sns</span><span class="o">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df_urls_numerical</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s1">&#39;muted&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Violin Plot of </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Label&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">feature</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Here are some examples of the generated violin plots:</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_14.png"
	width="846"
	height="547"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_14_hu43dcfe1bda49455b443d25e67996ff2e_36543_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_14_hu43dcfe1bda49455b443d25e67996ff2e_36543_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="154"
		data-flex-basis="371px"
	
></p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_15.png"
	width="846"
	height="547"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_15_hu878c31ea86649e28948941e22b26e77d_31277_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_15_hu878c31ea86649e28948941e22b26e77d_31277_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="154"
		data-flex-basis="371px"
	
></p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_16.png"
	width="850"
	height="547"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_16_hu28779847a74ddbfaa9719ce1fe60db0d_34050_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_16_hu28779847a74ddbfaa9719ce1fe60db0d_34050_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="155"
		data-flex-basis="372px"
	
></p>
<h4 id="interactive-box-plots">
    <a href="#interactive-box-plots">#</a>
    Interactive Box Plots
</h4><p>Plot for the top 5 features that have the highest correlation with the target.</p>
<p><strong>NOTE</strong>: To view the interactive plot, you MUST run the code below. The plot is not saved as an image in the notebook, so you won&rsquo;t be able to see it if you don&rsquo;t run the code.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">corr_target_top_5</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">box</span><span class="p">(</span><span class="n">df_urls_numerical</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">column</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">df_target</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="statistical-tests">
    <a href="#statistical-tests">#</a>
    Statistical Tests
</h4><p>For all numerical features, perform t-tests to compare means:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">numerical_t_results</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># skip label</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">feature</span> <span class="o">==</span> <span class="s1">&#39;label&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">continue</span>
</span></span><span class="line"><span class="cl">    <span class="n">phishing</span> <span class="o">=</span> <span class="n">df_features_numerical</span><span class="p">[</span><span class="n">df_target</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="n">feature</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">non_phishing</span> <span class="o">=</span> <span class="n">df_features_numerical</span><span class="p">[</span><span class="n">df_target</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="n">feature</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">t_stat</span><span class="p">,</span> <span class="n">p_val</span> <span class="o">=</span> <span class="n">ttest_ind</span><span class="p">(</span><span class="n">phishing</span><span class="p">,</span> <span class="n">non_phishing</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;T-test for </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2">: Stat=</span><span class="si">{</span><span class="n">t_stat</span><span class="si">}</span><span class="s2">, P-value=</span><span class="si">{</span><span class="n">p_val</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">numerical_t_results</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">t_stat</span><span class="p">,</span> <span class="n">p_val</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="most-important-numerical-features">
    <a href="#most-important-numerical-features">#</a>
    Most Important Numerical Features
</h4><p>Features with small p-values are considered more important for our classification model.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## top features with the smallest p-value</span>
</span></span><span class="line"><span class="cl"><span class="n">numerical_t_results_sorted</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">numerical_t_results</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">numerical_t_results_sorted</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>That gives us</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">[(&#39;CharContinuationRate&#39;, (-256.9673224005409, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;DegitRatioInURL&#39;, (232.61796808324493, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;DomainLength&#39;, (143.36142600843974, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;DomainTitleMatchScore&#39;, (-350.1667834107168, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;LetterRatioInURL&#39;, (192.05733596392525, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;LineOfCode&#39;, (-137.3940419972396, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;NoOfDegitsInURL&#39;, (87.82689697158546, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;NoOfEmptyRef&#39;, (-53.36214828900374, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;NoOfExternalRef&#39;, (-130.00859090242156, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;NoOfImage&#39;, (-138.7039740466059, 0.0))]
</span></span></code></pre></td></tr></table>
</div>
</div><ol>
<li>
<p><strong><code>SpacialCharRatioInURL</code>, <code>DegitRatioInURL</code>, <code>LetterRatioInURL</code>, <code>NoOfOtherSpecialCharsInURL</code>:</strong></p>
<p>This aligns with my personal experience that phishing URLs frequently use special characters, digits, and unusual letter combinations to mimic legitimate URLs, or to create confusing URLs that are more likely to deceive users.</p>
</li>
<li>
<p><strong><code>DomainLength</code>, <code>NoOfLettersInURL</code>, <code>URLLength</code>:</strong></p>
<p>These features being important makes sense because longer URLs are often used by phishers to hide malicious subdomains or paths that resemble legitimate addresses.</p>
</li>
<li>
<p><strong><code>NoOfDegitsInURL</code>, <code>NoOfQMarkInURL</code>:</strong></p>
<p>Phishing URLs may contain some digits in the url to resemble legitimate URLs. For example, if phishers want to peform phishing against UPenn students, the <code>upenn.edu</code> domain is appearently already registered, so they may register <code>upenn1[.]com</code> or <code>upenn2024[.]education</code> to trick users.</p>
</li>
<li>
<p><strong><code>TLDLength</code>:</strong></p>
<p>Abnormal TLD lengths can indicate less common or exotic TLDs used by phishers to create credible-looking URLs, for example, <code>upenn-pay[.]com</code> or <code>upenn-login[.]education</code>.</p>
</li>
</ol>
<h4 id="weakest-numerical-features">
    <a href="#weakest-numerical-features">#</a>
    Weakest Numerical Features
</h4><p>These are the features that have the weakest statistical significance.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## top 5 features with the largest p-value</span>
</span></span><span class="line"><span class="cl"><span class="n">numerical_t_results_sorted</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">:]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>That gives us</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">[(&#39;DomainPrice&#39;, (-20.15339051241565, 2.9952761186943435e-90)),
</span></span><span class="line"><span class="cl"> (&#39;LargestLineLength&#39;, (19.979571665743187, 9.826104450198757e-89)),
</span></span><span class="line"><span class="cl"> (&#39;NoOfAmpersandInURL&#39;, (16.821978666871274, 1.834605816231233e-63)),
</span></span><span class="line"><span class="cl"> (&#39;NoOfObfuscatedChar&#39;, (7.437398819558432, 1.0303278198240061e-13)),
</span></span><span class="line"><span class="cl"> (&#39;NoOfSubDomain&#39;, (2.8917740201365536, 0.0038310837128889526))]
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="understanding-categorical-features">
    <a href="#understanding-categorical-features">#</a>
    Understanding Categorical Features
</h3><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## combine df_features_categorical and df_target</span>
</span></span><span class="line"><span class="cl"><span class="n">df_urls_categorical_visual</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_features_categorical</span><span class="p">,</span> <span class="n">df_target</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>For the categorical labels, let&rsquo;s visualize the distribution of the features against the target label.</p>
<p><strong>What are we looking for here?</strong> We are looking for features that have a significant difference between counts of phishing and non-phishing URLs. If one has very distinct difference, this feature could play a significant role in impacting the target label.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## descriptive text for the label</span>
</span></span><span class="line"><span class="cl"><span class="n">df_urls_categorical_visual</span><span class="p">[</span><span class="s1">&#39;label_text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_urls_categorical_visual</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;Non-Phishing&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;Phishing&#39;</span><span class="p">})</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Skip columns with too many unique values,</span>
</span></span><span class="line"><span class="cl"><span class="c1">##for example urls here is not useful for direct comparison</span>
</span></span><span class="line"><span class="cl"><span class="n">skipped_column_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;TLD&#39;</span><span class="p">,</span> <span class="s1">&#39;PublicSuffix&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;label_text&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">df_urls_categorical_visual</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">column</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">skipped_column_names</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_urls_categorical_visual</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">column</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&#34;label_text&#34;</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s2">&#34;Set1&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Distribution of </span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Label&#39;</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.05</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">borderaxespad</span><span class="o">=</span><span class="mf">0.</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="statistical-testing-for-categorical-features">
    <a href="#statistical-testing-for-categorical-features">#</a>
    Statistical Testing for Categorical Features
</h3><p>The visualization above is useful to get a feeling of the distribution of the categorical features and their significance in relationship with the target label.</p>
<p>Now, let&rsquo;s perform statistical tests to confirm the significance of the features.</p>
<p>Here we use <a class="link" href="https://www.geeksforgeeks.org/chi-square-test-for-feature-selection-mathematical-explanation/"  target="_blank" rel="noopener"
    >Chi-test</a>, which is primarily used to examine whether two categorical variables (two dimensions of the contingency table) are independent in influencing the test statistic (values within the table)</p>
<p>Mathematically, a Chi-Square test is done on two distributions two determine the level of similarity of their respective variances. In its null hypothesis, it assumes that the given distributions are independent. This test thus can be used to determine the best features for a given dataset by determining the features on which the output class label is most dependent. For each feature in the dataset, the $\chi ^{2}$  is calculated and then ordered in descending order according to the $\chi ^{2}$  value. The higher the value of $\chi ^{2}$ , the more dependent the output label is on the feature and higher the importance the feature has on determining the output. Let the feature in question have m attribute values and the output have k class labels. Then the value of $\chi ^{2}$  is given by the following expression:</p>
<p>$\chi ^{2} = \sum {i=1}^{m} \sum {j=1}^{k}\frac{(O{ij}-E{ij})^{2}}{E_{ij}}$</p>
<p>where $O_{ij}$  – Observed frequency $E_{ij}$  – Expected frequency For each feature, a contingency table is created with m rows and k columns. Each cell (i,j) denotes the number of rows having attribute feature as i and class label as k. Thus each cell in this table denotes the observed frequency. (<a class="link" href="https://www.geeksforgeeks.org/chi-square-test-for-feature-selection-mathematical-explanation/"  target="_blank" rel="noopener"
    >source</a>)</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">perform_chi2_test</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">feature</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">contingency_table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">feature</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">chi2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dof</span><span class="p">,</span> <span class="n">expected</span> <span class="o">=</span> <span class="n">chi2_contingency</span><span class="p">(</span><span class="n">contingency_table</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Chi-squared test for </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2">:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Chi2 Statistic: </span><span class="si">{</span><span class="n">chi2</span><span class="si">}</span><span class="s2">, P-value: </span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">chi2</span><span class="p">,</span> <span class="n">p</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">chi2_stats</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Perform test for each categorical feature</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">df_urls_categorical_visual</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">column</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;label_text&#39;</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">        <span class="n">chi2</span><span class="p">,</span><span class="n">p</span> <span class="o">=</span> <span class="n">perform_chi2_test</span><span class="p">(</span><span class="n">df_urls_categorical_visual</span><span class="p">,</span> <span class="n">column</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">chi2_stats</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">chi2</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>To help us better understand the importance, let&rsquo;s rank them by their $\chi ^{2}$ values.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Order by significance</span>
</span></span><span class="line"><span class="cl"><span class="n">chi2_stats_sorted</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">chi2_stats</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">chi2_stats_sorted</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">[(&#39;HasSocialNet&#39;, (145023.7420316948, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;HasCopyrightInfo&#39;, (130292.68757967741, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;HasDescription&#39;, (112334.62388393158, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;PublicSuffix&#39;, (90887.69233733535, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;IsHTTPS&#39;, (87486.78604118452, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;HasSubmitButton&#39;, (78925.93676851525, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;TLD&#39;, (72390.61558625728, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;IsResponsive&#39;, (70964.98848503799, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;HasHiddenFields&#39;, (60783.768711655066, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;HasFavicon&#39;, (57473.0059661682, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;HasTitle&#39;, (49831.82697877125, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;Robots&#39;, (36346.1017555631, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;Pay&#39;, (30514.30996266347, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;Bank&#39;, (8418.032312347743, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;HasExternalFormSubmit&#39;, (6619.679733768652, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;HasPasswordField&#39;, (4501.468438718974, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;Crypto&#39;, (2338.26408286789, 0.0)),
</span></span><span class="line"><span class="cl"> (&#39;NoOfSelfRedirect&#39;, (1377.8103615413584, 1.3941584604567876e-301)),
</span></span><span class="line"><span class="cl"> (&#39;IsDomainIP&#39;, (852.260590396482, 2.3448225852057846e-187)),
</span></span><span class="line"><span class="cl"> (&#39;HasObfuscation&#39;, (646.896659124284, 1.0568883774203827e-142)),
</span></span><span class="line"><span class="cl"> (&#39;NoOfURLRedirect&#39;, (508.61027713202554, 1.2722702420876379e-112))]
</span></span></code></pre></td></tr></table>
</div>
</div><p>The Chi-Square test results show that the top features that have the highest $\chi ^{2}$ values are:</p>
<ol>
<li>
<p><strong><code>HasSocialNet</code> (Chi2 Statistic: 145023.7420316948, P-value: 0.0)</strong>:</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_17.png"
	width="915"
	height="395"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_17_hu6847d0265a54e3a9bbacab4255e294e0_26831_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_17_hu6847d0265a54e3a9bbacab4255e294e0_26831_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="231"
		data-flex-basis="555px"
	
></p>
<p>This feature shows us whether a website includes social network links, which is typical for legitimate sites as they often connect to many social media platforms for marketing purposes. For example, we know that UPenn&rsquo;s website <a class="link" href="https://www.upenn.edu/"  target="_blank" rel="noopener"
    >https://www.upenn.edu</a> typically has links to their Facebook, Twitter, and Instagram pages, etc. The phishign sites, as you may expect, are less likely to include these links, as most of them are not interested in promoting their site on social media.</p>
</li>
<li>
<p><strong><code>HasCopyrightInfo</code> (Chi2 Statistic: 130292.68757967741, P-value: 0.0)</strong>:</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_18.png"
	width="915"
	height="395"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_18_hu2b7f2c1680cabd0481bc789d6d061689_26963_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_18_hu2b7f2c1680cabd0481bc789d6d061689_26963_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="231"
		data-flex-basis="555px"
	
></p>
<p>Copyright information adds legitimacy to a website by indicating ownership and the legality of content, which is another common indication of a legitimate site.</p>
<p>For example, UPenn&rsquo;s website <a class="link" href="https://www.upenn.edu/"  target="_blank" rel="noopener"
    >https://www.upenn.edu</a> has the following copyright information in the footer:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-html" data-lang="html"><span class="line"><span class="cl"><span class="p">&lt;</span><span class="nt">p</span> <span class="na">style</span><span class="o">=</span><span class="s">&#34;text-align: center;&#34;</span><span class="p">&gt;&lt;</span><span class="nt">strong</span><span class="p">&gt;&lt;</span><span class="nt">a</span> <span class="na">href</span><span class="o">=</span><span class="s">&#34;&lt;https://www.seas.upenn.edu/&gt;&#34;</span><span class="p">&gt;</span>
</span></span><span class="line"><span class="cl">   PENN ENGINEERING <span class="p">&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>©2017<span class="p">&lt;/</span><span class="nt">strong</span><span class="p">&gt;</span>
</span></span><span class="line"><span class="cl"><span class="p">&lt;/</span><span class="nt">p</span><span class="p">&gt;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Phishing sites woudn&rsquo;t bother adding these info on their website.</p>
</li>
<li>
<p><strong><code>HasDescription</code> (Chi2 Statistic: 112334.62388393158, P-value: 0.0)</strong>:</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_19.png"
	width="915"
	height="395"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_19_hu4b55ad2928d119c68479876966e1bce6_27625_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_19_hu4b55ad2928d119c68479876966e1bce6_27625_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="231"
		data-flex-basis="555px"
	
></p>
<p>Meta descriptions in the headers usually, if SEO is done right, provide a summary of the website&rsquo;s content on search engine results.</p>
<p>For example, <a class="link" href="https://www.seas.upenn.edu/"  target="_blank" rel="noopener"
    >https://www.seas.upenn.edu</a> has the following meta description in the header:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-html" data-lang="html"><span class="line"><span class="cl"><span class="p">&lt;</span><span class="nt">meta</span> <span class="na">name</span><span class="o">=</span><span class="s">&#34;description&#34;</span> <span class="na">content</span><span class="o">=</span><span class="s">&#34;Penn Engineering | Inventing the Future&#34;</span><span class="p">&gt;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Again, a phishing site wouldn&rsquo;t bother with SEO aspect of things on their websites.</p>
</li>
<li>
<p><strong><code>HasSubmitButton</code> (Chi2 Statistic: 78925.93676851525, P-value: 0.0)</strong>:</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_20.png"
	width="906"
	height="395"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_20_huda9d9f9a850278364385312c0516d76b_26847_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_20_huda9d9f9a850278364385312c0516d76b_26847_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="229"
		data-flex-basis="550px"
	
></p>
<p>The presence of a submit button is common in forms where user input is required. Legitimate sites design these elements to be user-friendly and secure. Phishing sites often have forms designed to harvest data, so there is a higher chance of them having submit buttons.</p>
</li>
<li>
<p><strong><code>IsHTTPS</code> (Chi2 Statistic: 87486.78604118452, P-value: 0.0)</strong>:</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_21.png"
	width="915"
	height="395"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_21_hu0b15fee0c63af100a3e46e4d82f84d41_25566_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_21_hu0b15fee0c63af100a3e46e4d82f84d41_25566_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="231"
		data-flex-basis="555px"
	
></p>
<p>HTTPS indicates that a site uses a secure protocol with installed SSL cert to encrypt data between the user and the server. Many phishing sites now also use HTTPS to appear legitimate, at least for those ones I personally encountered. The significant chi-squared statistic shows this feature is statistically significant for distinguishing between phishing and non-phishing sites.</p>
</li>
<li>
<p><strong><code>HasFavicon</code> (Chi2 Statistic: 57473.0059661682, P-value: 0.0)</strong>:</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_22.png"
	width="906"
	height="395"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_22_hu1f0859ad232b26e2ff3dcc217bbed775_25380_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_22_hu1f0859ad232b26e2ff3dcc217bbed775_25380_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="229"
		data-flex-basis="550px"
	
></p>
<p>Favicons are small icons associated with a website, typically displayed in browser tabs and bookmarks. For example, visiting UPenn website <a class="link" href="https://www.upenn.edu/"  target="_blank" rel="noopener"
    >https://www.upenn.edu</a> will show you the UPenn logo in the browser tab. Phishing sites might not use custom favicons.</p>
</li>
</ol>
<h3 id="tld-phishing-abuse-analysis-over-the-tld-field">
    <a href="#tld-phishing-abuse-analysis-over-the-tld-field">#</a>
    TLD Phishing Abuse Analysis over the <code>TLD</code> field
</h3><p>Top-level domains (TLDs), which are the final segments of a domain name, are frequently utilized by malicious actors. They often create domains with TLDs that mimic well-known and trusted extensions, deceiving users into visiting counterfeit websites (Anon, 2023a).</p>
<p>The introduction of new TLDs like <code>.zip</code> and <code>.mov</code> has enabled cybercriminals to register domains that look like familiar file extensions. This can mislead users into thinking they are downloading a safe file, when in fact, they are being directed to a phishing URL.</p>
<p>Shortly after the release of these TLDs, numerous phishing domains were registered (Anon, 2023b). Phishers commonly use TLDs that mirror well-known brands or trusted entities to trick users into believing they are accessing legitimate websites. (<a class="link" href="https://www.sciencedirect.com/science/article/pii/S0167404823004558"  target="_blank" rel="noopener"
    >source</a>)</p>
<p>So, let&rsquo;s analyze the <code>TLD</code> field to see if there are any patterns that we can identify.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## List the top 20 most frequentlt abused TLDs</span>
</span></span><span class="line"><span class="cl"><span class="n">df_urls_categorical_phishing</span> <span class="o">=</span> <span class="n">df_urls_categorical_visual</span><span class="p">[</span><span class="n">df_urls_categorical_visual</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># 0 is phishing</span>
</span></span><span class="line"><span class="cl"><span class="n">top_phishing_tlds</span> <span class="o">=</span> <span class="n">df_urls_categorical_phishing</span><span class="p">[</span><span class="s1">&#39;TLD&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1">## top_phishing_tlds</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## histogram for top_phishing_tlds</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">top_phishing_tlds</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">top_phishing_tlds</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Top 50 Most Frequently Abused TLDs&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Top Level Domains&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Count&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_23.png"
	width="868"
	height="575"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_23_hu032f2b410544c871da9f026f40e55f33_34348_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_23_hu032f2b410544c871da9f026f40e55f33_34348_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="150"
		data-flex-basis="362px"
	
></p>
<h3 id="the-most-abused-cctlds-country-code-tlds">
    <a href="#the-most-abused-cctlds-country-code-tlds">#</a>
    The Most Abused ccTLDs (country code TLDs)
</h3><p>ccTLD is a top-level domain that is generally reserved or used for a country or a dependent territory.</p>
<p>For example, <code>.us</code> is the ccTLD for the United States. The ccTLDs are assigned by the Internet Assigned Numbers Authority (IANA) to the national governments of countries and are always two letters long.</p>
<p>For more info about ccTLD: <a class="link" href="https://icannwiki.org/Country_code_top-level_domain"  target="_blank" rel="noopener"
    >https://icannwiki.org/Country_code_top-level_domain</a></p>
<p>So, let&rsquo;s filter for the domains that have ccTLDs.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Filter for only ccTLDs (2 chars) from TLDs</span>
</span></span><span class="line"><span class="cl"><span class="n">df_urls_categorical_cctlds</span> <span class="o">=</span> <span class="n">df_urls_categorical_visual</span><span class="p">[</span><span class="n">df_urls_categorical_visual</span><span class="p">[</span><span class="s1">&#39;TLD&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Number of ccTLDs: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df_urls_categorical_cctlds</span><span class="p">)</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1">## Number of ccTLDs: 69596</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## List the top 20 most frequently abused ccTLDs</span>
</span></span><span class="line"><span class="cl"><span class="n">df_urls_categorical_phishing_cctlds</span> <span class="o">=</span> <span class="n">df_urls_categorical_cctlds</span><span class="p">[</span><span class="n">df_urls_categorical_cctlds</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># 0 is phishing</span>
</span></span><span class="line"><span class="cl"><span class="n">top_phishing_cctlds</span> <span class="o">=</span> <span class="n">df_urls_categorical_phishing_cctlds</span><span class="p">[</span><span class="s1">&#39;TLD&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">top_phishing_cctlds</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">##get a list of countries and a list of counts</span>
</span></span><span class="line"><span class="cl"><span class="n">abused_cctld_countries</span> <span class="o">=</span> <span class="n">top_phishing_cctlds</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">abused_cctld_counts</span> <span class="o">=</span> <span class="n">top_phishing_cctlds</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## histogram for top_phishing_cctlds</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">top_phishing_cctlds</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">top_phishing_cctlds</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Top 50 Most Frequently Abused ccTLDs&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Country Top Level Domains&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Count&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_24.png"
	width="859"
	height="555"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_24_hu59d662620d75c376fe294c9cb25d27e8_32183_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_24_hu59d662620d75c376fe294c9cb25d27e8_32183_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="154"
		data-flex-basis="371px"
	
></p>
<h4 id="global-heat-map-of-cctld-phishing-abuse-counts">
    <a href="#global-heat-map-of-cctld-phishing-abuse-counts">#</a>
    Global Heat Map of ccTLD Phishing Abuse Counts
</h4><p>Finally, let&rsquo;s visualize the global distribution of the ccTLD abuse counts on a world map.</p>
<p>Because the <code>plotly</code> package supports only 3 letter country codes, we need to map the 2 letter country codes to 3 letter country codes using the <code>pycountry</code> package.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pycountry</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## convet two-letter codes to three-letter ISO codes</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">alpha2_to_alpha3</span><span class="p">(</span><span class="n">alpha2</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">country</span> <span class="o">=</span> <span class="n">pycountry</span><span class="o">.</span><span class="n">countries</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">alpha_2</span><span class="o">=</span><span class="n">alpha2</span><span class="o">.</span><span class="n">upper</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Country: </span><span class="si">{</span><span class="n">country</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">country</span><span class="o">.</span><span class="n">alpha_3</span> <span class="k">if</span> <span class="n">country</span> <span class="k">else</span> <span class="kc">None</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Plot a global map based on the two digit country codes:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Create a DataFrame for plotting</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;Country&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">alpha2_to_alpha3</span><span class="p">(</span><span class="n">cc</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="k">for</span> <span class="n">cc</span> <span class="ow">in</span> <span class="n">abused_cctld_countries</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;Counts&#39;</span><span class="p">:</span> <span class="n">abused_cctld_counts</span>
</span></span><span class="line"><span class="cl"><span class="p">})</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Plot a global map based on the two digit country codes</span>
</span></span><span class="line"><span class="cl"><span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">choropleth</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">data_frame</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">locations</span><span class="o">=</span><span class="s1">&#39;Country&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">locationmode</span><span class="o">=</span><span class="s1">&#39;ISO-3&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;Counts&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Global Map of Most Abused ccTLDs&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">hover_name</span><span class="o">=</span><span class="s1">&#39;Country&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">color_continuous_scale</span><span class="o">=</span><span class="n">px</span><span class="o">.</span><span class="n">colors</span><span class="o">.</span><span class="n">sequential</span><span class="o">.</span><span class="n">Bluered</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;natural earth&#39;</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_25.png"
	width="1223"
	height="450"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_25_hu5960927d2de6b092470a79ea6a3f4115_77304_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_25_hu5960927d2de6b092470a79ea6a3f4115_77304_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="271"
		data-flex-basis="652px"
	
></p>
<p>The following bullet list provides a brief overview of some of the most abused country code top-level domains (ccTLDs):</p>
<ul>
<li><strong>Colombia (.co)</strong>: 4964 instances</li>
<li><strong>British Indian Ocean Territory (.io)</strong>: 3769 instances</li>
<li><strong>Russia (.ru)</strong>: 2983 instances</li>
<li><strong>Central African Republic (.cf)</strong>: 1203 instances</li>
<li><strong>Gabon (.ga)</strong>: 1107 instances</li>
<li><strong>Mali (.ml)</strong>: 994 instances</li>
<li><strong>Montenegro (.me)</strong>: 853 instances</li>
<li><strong>Poland (.pl)</strong>: 802 instances</li>
<li><strong>China (.cn)</strong>: 690 instances</li>
<li><strong>Germany (.de)</strong>: 686 instances</li>
<li><strong>Brazil (.br)</strong>: 653 instances</li>
<li><strong>Philippines (.ph)</strong>: 608 instances</li>
<li><strong>Indonesia (.id)</strong>: 560 instances</li>
<li><strong>India (.in)</strong>: 537 instances</li>
</ul>
<hr>
<h2 id="logistic-regression">
    <a href="#logistic-regression">#</a>
    <strong>Logistic Regression</strong>
</h2><p>In this analysis, we first use the basic Logistic Regression for binary classification task.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Use the model to predict on the test set and save these predictions as `y_pred`</span>
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Find the accuracy and store the value in `log_acc`</span>
</span></span><span class="line"><span class="cl"><span class="n">log_acc</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;accuracy: </span><span class="si">{</span><span class="n">log_acc</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## accuracy: 0.9971302958763907</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The accuracy of the Logistic Regression model, as determined by comparing the predicted labels against the actual labels in <strong><code>y_test</code></strong>, is impressively high at approximately 99.71%.</p>
<h3 id="pca-to-reduce-dimensionality">
    <a href="#pca-to-reduce-dimensionality">#</a>
    <strong>PCA to Reduce Dimensionality</strong>
</h3><p>Before proceeding with another round of Logistic Regression, we apply Principal Component Analysis (PCA) to reduce the dimensionality of the feature set. PCA is a statistical technique that transforms a large set of variables into a smaller one that still contains most of the information in the large set.</p>
<p>First, the feature set is standardized to ensure that PCA&rsquo;s performance is not biased by the nature of scale invariance.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">std_s</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train_scaler</span> <span class="o">=</span> <span class="n">std_s</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_test_scaler</span> <span class="o">=</span> <span class="n">std_s</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Instantiate and Fit PCA</span>
</span></span><span class="line"><span class="cl"><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">X_train_scaler</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">pca_x_train</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Save the explained variance ratios</span>
</span></span><span class="line"><span class="cl"><span class="n">explained_variance_ratios</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Save the CUMULATIVE explained variance ratios </span>
</span></span><span class="line"><span class="cl"><span class="n">cum_evr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">explained_variance_ratios</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>By examining the cumulative explained variance ratio, we determine the number of components that account for 80% of the variance in the dataset:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="cl"><span class="n">thresh</span> <span class="o">=</span> <span class="mf">0.8</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Plotting</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">len</span><span class="p">(</span><span class="n">cum_evr</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y</span><span class="o">=</span><span class="n">cum_evr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Cumulative Explained Variance&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">len</span><span class="p">(</span><span class="n">cum_evr</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="n">thresh</span><span class="p">]</span> <span class="o">*</span> <span class="n">len</span><span class="p">(</span><span class="n">cum_evr</span><span class="p">),</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;80% Threshold&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Components&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Cumulative Explained Variance Ratio&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Cumulative Explained Variance Ratio vs. Number of Components&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">ticks</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">len</span><span class="p">(</span><span class="n">explained_variance_ratios</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">len</span><span class="p">(</span><span class="n">explained_variance_ratios</span><span class="p">)</span> <span class="o">//</span> <span class="mi">10</span><span class="p">)))</span>  <span class="c1"># Adjust step for readability</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_26.png"
	width="691"
	height="547"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_26_hue9592299fce0f877cfd4eebae07b2b63_42276_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_26_hue9592299fce0f877cfd4eebae07b2b63_42276_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="126"
		data-flex-basis="303px"
	
></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">num_components</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Transform on Testing Set</span>
</span></span><span class="line"><span class="cl"><span class="n">X_test_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="logistic-regression-with-pca">
    <a href="#logistic-regression-with-pca">#</a>
    <strong>Logistic Regression with PCA</strong>
</h2><p>After reducing the dimensionality, Logistic Regression is applied again on this transformed dataset. The model is trained on the PCA-transformed training set and evaluated against the PCA-transformed test set.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">log_reg_pca</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">log_reg_pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Use the model to predict on the PCA transformed test set and save these predictions as `y_pred`</span>
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">log_reg_pca</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_pca</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">##Find the accuracy and store the value in `test_accuracy`</span>
</span></span><span class="line"><span class="cl"><span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">log_reg_pca</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_pca</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;accuracy: </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## accuracy: 0.9979219383932484</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The accuracy after applying PCA is slightly reduced to approximately 99.79% compared to the original Logistic Regression model.</p>
<h2 id="ridge-regression">
    <a href="#ridge-regression">#</a>
    <strong>Ridge Regression</strong>
</h2><p>Ridge regression is effective in handling multicollinearity (high correlation among independent variables) and overfitting, which are common issues in high-dimensional datasets.</p>
<p>By incorporating a degree of bias into the regression estimates through the regularization term, ridge regression reduces the model&rsquo;s variance and makes it less susceptible to noise in the training data.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Split the data into training and testing sets</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df_features_encoded</span><span class="p">,</span> <span class="n">df_target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Standardize the feature data since regularization is sensitive to the scale of input features</span>
</span></span><span class="line"><span class="cl"><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Create Ridge Regression model</span>
</span></span><span class="line"><span class="cl"><span class="n">ridge_reg</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>  <span class="c1"># alpha is the regularization strength; larger values specify stronger regularization</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Fit the model</span>
</span></span><span class="line"><span class="cl"><span class="n">ridge_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Predict on the test data</span>
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">ridge_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Evaluate the model using RMSE</span>
</span></span><span class="line"><span class="cl"><span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Root Mean Squared Error: </span><span class="si">{</span><span class="n">rmse</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">coefficients</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">ridge_reg</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df_features_encoded</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Coefficient&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">coefficients</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;Coefficient&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">Root</span> <span class="n">Mean</span> <span class="n">Squared</span> <span class="n">Error</span><span class="p">:</span> <span class="mf">0.12415411373986451</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>The RMSE value confirms the model&rsquo;s effectiveness in predicting phishing URLs with a small average error, implying reliability in practical applications. The analysis of coefficients allows understanding the influence of different features on the phishing likelihood. It shows that the model effectively captures both intuitive and non-intuitive relationships within the data.</li>
<li>URLLength (1.220800): The positive coefficient of URLLength indicates that longer URLs are likely associated with phishing. This aligns with typical phishing behavior where longer URLs may be used to obfuscate dubious parts of the URL or to mimic complex legitimate URLs.</li>
<li>NoOfDegitsInURL (-0.355845) and NoOfLettersInURL (-0.849399): These features having negative coefficients suggest that a higher count of digits or letters reduces the likelihood of a URL being phishing, which might indicate that shorter, simpler URLs (with fewer characters) are often safer.</li>
</ul>
<h2 id="linear-regression-unregularized">
    <a href="#linear-regression-unregularized">#</a>
    <strong>Linear Regression (Unregularized)</strong>
</h2><p>Linear Regression is straightforward and one of the most easily interpretable models for regression tasks:</p>
<ul>
<li>The coefficients directly show the expected change in the target variable with a one-unit change in the feature.</li>
<li>It can handle large datasets.</li>
<li>It&rsquo;s generally fast to train, especially when compared to more complex models that require iterative processes to converge.</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Split the data into training and testing sets</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df_features_encoded</span><span class="p">,</span> <span class="n">df_target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Initialize the Linear Regression model</span>
</span></span><span class="line"><span class="cl"><span class="n">linear_reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Fit the model on the training data</span>
</span></span><span class="line"><span class="cl"><span class="n">linear_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Predict on the test data</span>
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">linear_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Evaluate the model using Mean Squared Error</span>
</span></span><span class="line"><span class="cl"><span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Mean Squared Error: </span><span class="si">{</span><span class="n">mse</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Optionally, display the model coefficients</span>
</span></span><span class="line"><span class="cl"><span class="n">coefficients</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">linear_reg</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="n">df_features_encoded</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Coefficients&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">coefficients</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;Coefficients&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">Mean</span> <span class="n">Squared</span> <span class="n">Error</span><span class="p">:</span> <span class="mf">0.015373646065718673</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The low MSE indicate a good fit, and the analysis of coeffients can indicate the influence of each feature on the prediction.</p>
<p>However, given the model&rsquo;s lack of regularization and the dataset&rsquo;s high dimensionality, there is a risk of overfitting.</p>
<h2 id="linear-regression-unregularized-with-pca">
    <a href="#linear-regression-unregularized-with-pca">#</a>
    <strong>Linear Regression (Unregularized) with PCA</strong>
</h2><p>PCA is used to reduce the number of features in a dataset by transforming the original features into a new set of variables, which are linear combinations of the original features.</p>
<p>PCA helps in mitigating issues like multicollinearity among features by ensuring that the principal components are orthogonal (independent of each other).</p>
<p>This independence is crucial for models like Linear Regression, which assume little or no multicollinearity among independent variables.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Standardize features (important for PCA)</span>
</span></span><span class="line"><span class="cl"><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">features_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_features_encoded</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Split the data into training and testing sets</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">features_scaled</span><span class="p">,</span> <span class="n">df_target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Initialize PCA</span>
</span></span><span class="line"><span class="cl"><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_test_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Check how many components were selected</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;PCA selected </span><span class="si">{</span><span class="n">pca</span><span class="o">.</span><span class="n">n_components_</span><span class="si">}</span><span class="s2"> components&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Initialize the Linear Regression model</span>
</span></span><span class="line"><span class="cl"><span class="n">linear_reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Fit the model on the training data</span>
</span></span><span class="line"><span class="cl"><span class="n">linear_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Predict on the test data</span>
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">linear_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_pca</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Evaluate the model using Mean Squared Error and R-squared</span>
</span></span><span class="line"><span class="cl"><span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Mean Squared Error: </span><span class="si">{</span><span class="n">mse</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;R-squared: </span><span class="si">{</span><span class="n">r2</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">PCA</span> <span class="n">selected</span> <span class="mi">1739</span> <span class="n">components</span>
</span></span><span class="line"><span class="cl"><span class="n">Mean</span> <span class="n">Squared</span> <span class="n">Error</span><span class="p">:</span> <span class="mf">0.026263884226329685</span>
</span></span><span class="line"><span class="cl"><span class="n">R</span><span class="o">-</span><span class="n">squared</span><span class="p">:</span> <span class="mf">0.8926387776461615</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>Mean Squared Error (MSE) of 0.026263884226329685: This MSE is higher than the previous model without PCA (which had an MSE of 0.015373646065718673). While this indicates a slight decrease in the accuracy per prediction, it&rsquo;s essential to consider that this might be an acceptable trade-off for the benefits of dimensionality reduction, such as simpler models and faster computation times.</li>
<li>R-squared of 0.8926387776461615: This is a strong R-squared value, indicating that approximately 89.26% of the variance in the target variable is predictable from the independent variables (principal components in this case).</li>
<li>High R-squared values suggest a good fit of the model to the data, confirming that despite the increase in MSE, the model with PCA still explains a significant portion of the variance.</li>
</ul>
<h2 id="random-forest-classifier">
    <a href="#random-forest-classifier">#</a>
    <strong>Random Forest Classifier</strong>
</h2><p>Next, we use a Random Forest Classifier, which is a nice method known for its high accuracy and ability to operate over complex datasets with a mixture of categorical and numerical data.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Initialize model with default parameters and fit it on the training set</span>
</span></span><span class="line"><span class="cl"><span class="n">rfc</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">class_weight</span> <span class="o">=</span> <span class="s2">&#34;balanced&#34;</span><span class="p">,</span> <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">120</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">rfc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">##Use the model to predict on the test set and save these predictions as `y_pred`</span>
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">rfc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Find the accuracy and store the value in `rf_acc`</span>
</span></span><span class="line"><span class="cl"><span class="n">rf_acc</span> <span class="o">=</span> <span class="n">rfc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;accuracy: </span><span class="si">{</span><span class="n">rf_acc</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## accuracy: 0.9999717270529693</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>We observe an even higher accuracy of nearly 100% (99.997%).</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">p</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cm</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&#34;YlGnBu&#34;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Actual Label&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted Label&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_27.png"
	width="666"
	height="593"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_27_hu4e9a0c0769b1c6e15ca79c8ff8ee9aed_29155_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_27_hu4e9a0c0769b1c6e15ca79c8ff8ee9aed_29155_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="112"
		data-flex-basis="269px"
	
></p>
<h2 id="random-forest-regression">
    <a href="#random-forest-regression">#</a>
    <strong>Random Forest Regression</strong>
</h2><p>Random Forest can handle large datasets with thousands of features and potentially complex nonlinear relationships without feature selection or dimensionality reduction.</p>
<p>It naturally models interactions between features, making it effective in cases where the predictive power arises from the combination of features.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Split the data into training and testing sets</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df_features_encoded</span><span class="p">,</span> <span class="n">df_target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Initialize the Random Forest Regressor</span>
</span></span><span class="line"><span class="cl"><span class="n">random_forest_regressor</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Fit the model on the training data</span>
</span></span><span class="line"><span class="cl"><span class="n">random_forest_regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Predict on the test data</span>
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">random_forest_regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Evaluate the model using Mean Squared Error and R-squared</span>
</span></span><span class="line"><span class="cl"><span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Mean Squared Error: </span><span class="si">{</span><span class="n">mse</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;R-squared: </span><span class="si">{</span><span class="n">r2</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>The Mean Squared Error: 2.1204860153947286e-09 is higher than the previous regression models. But it&rsquo;s still accetpble number for the model prediction.</li>
<li>The R-squared value is nearly to 1,indicating that most of the cariance in the target cariable is predictable from the independent variables.</li>
</ul>
<h2 id="decision-tree-classifier">
    <a href="#decision-tree-classifier">#</a>
    <strong>Decision Tree classifier</strong>
</h2><h3 id="preprocessing-and-pca">
    <a href="#preprocessing-and-pca">#</a>
    Preprocessing and PCA
</h3><h4 id="splitting-training-data">
    <a href="#splitting-training-data">#</a>
    Splitting Training Data
</h4><p>The dataset is prepared for model training by initially splitting it into training and test sets.</p>
<p>Here, we are following the standard practice in machine learning, the data is divided using a test size of 40%, with <strong><code>train_test_split</code></strong> ensuring random but consistent selections with a <strong><code>random_state</code></strong>.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df_features_encoded</span><span class="p">,</span> <span class="n">df_target</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                    <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.4</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>After splitting, the next step is to standardize the features.</p>
<p>We rescale the features so that they have the properties of a standard normal distribution with mean = 0, SD = 1. This is to make sure all features are centered around 0 and have variance in the same order.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Principal Component Analysis (PCA) is then applied to the scaled training data.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>PCA is a dimensionality reduction technique that transforms the original variables into a new set of variables, which are linear combinations of the original variables.</p>
<p>To understand how many principal components to retain, we examine the explained variance ratio provided by PCA.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Save the explained variance ratios into variable called &#34;explained_variance_ratios&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">explained_variance_ratios</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Save the CUMULATIVE explained variance ratios into variable called &#34;cum_evr&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">cum_evr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Typically, we look for the point where the cumulative explained variance ratio reaches a threshold that shows a good balance between information retention and model simplicity, which we set here at 70% (<code>thresh = 0.7</code>):</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">thresh</span> <span class="o">=</span> <span class="mf">0.7</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## find optimal num components to use (n) by plotting explained variance ratio (2 points)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">cum_evr</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y</span> <span class="o">=</span> <span class="n">cum_evr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">cum_evr</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y</span> <span class="o">=</span> <span class="n">thresh</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of components&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Cumulative explained_variance_ratio&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Cumulative explained variance ratio&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_28.png"
	width="691"
	height="547"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_28_hu8928905c09ae7896267a948b0424a99b_32823_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_28_hu8928905c09ae7896267a948b0424a99b_32823_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="126"
		data-flex-basis="303px"
	
></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">n_components_pca</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cum_evr</span> <span class="o">&gt;=</span> <span class="n">thresh</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl"><span class="n">n_components_pca</span>
</span></span><span class="line"><span class="cl"><span class="c1">## output: 1039</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>In this case, after plotting, it appears that 1039 components are required to explain 70% of the variance.</p>
<p>So, 1039 = the optimal number of principal components needed to capture the majority of variance in the data while reducing dimensionality.</p>
<p>Let’s reapply PCA with this specific number to transform both the training and testing datasets:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">n_components_pca</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_test_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>This transformation results in new training and testing sets that are now reduced in dimensionality but still capture the essence of the original datasets!</p>
<h3 id="decision-tree">
    <a href="#decision-tree">#</a>
    Decision tree
</h3><p>We start our exploration of decision tree classifiers by setting up a basic model using the default parameters.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Here we can print out the entire tree.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">dot_data</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">export_graphviz</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">out_file</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">graph</span> <span class="o">=</span> <span class="n">pydotplus</span><span class="o">.</span><span class="n">graph_from_dot_data</span><span class="p">(</span><span class="n">dot_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">create_png</span><span class="p">())</span>
</span></span><span class="line"><span class="cl"><span class="n">img</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>It shows the decision paths from the root to the leaves:</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_29.png"
	width="18658"
	height="3548"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_29_hu87ce9fc5cfc327bcbb96d34180340402_3437285_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_29_hu87ce9fc5cfc327bcbb96d34180340402_3437285_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="525"
		data-flex-basis="1262px"
	
></p>
<p>Next, we evaluate the model on the test dataset to assess its accuracy. Using this tree to predict test data, we get the following:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_pca</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;The test accuracy with basic decision tree is </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The test accuracy with basic decision tree is 0.9925464916558875</p>
<p>The reported accuracy from the basic decision tree is impressively high, at approximately 99.25%.</p>
<p>To further assess the model&rsquo;s performance, we analyze the confusion matrix:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">p</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cm</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&#34;YlGnBu&#34;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Actual Label&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted Label&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_30.png"
	width="666"
	height="593"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_30_hu578f6087d39a632481925a17718542c2_28052_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_30_hu578f6087d39a632481925a17718542c2_28052_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="112"
		data-flex-basis="269px"
	
></p>
<h4 id="optimizing-decision-tree-depth">
    <a href="#optimizing-decision-tree-depth">#</a>
    <strong>Optimizing Decision Tree Depth</strong>
</h4><p>To improve the decision tree model, we use cross-validation to determine the optimal tree depth.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">parameters = {&#39;max_depth&#39;: range(3, 15)}
</span></span><span class="line"><span class="cl">clf = GridSearchCV(tree.DecisionTreeClassifier(), parameters, n_jobs = -1)
</span></span><span class="line"><span class="cl">clf.fit(X = X_train_pca, y = y_train)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">tree_model = clf.best_estimator_
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">print(f&#34;The best parameter is {clf.best_params_} and the corresponding train score is {clf.best_score_}&#34;)
</span></span></code></pre></td></tr></table>
</div>
</div><p>The best parameter is {&lsquo;max_depth&rsquo;: 14} and the corresponding train score is 0.9943524447559969</p>
<p>We proceed to retrain our decision tree classifier using this optimized depth:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span> <span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_pca</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;The test accuracy with best max depth decision tree is </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The test accuracy with best max depth decision tree is 0.9932992641913526</p>
<p>The corresponding decision tree is a more balanced tree and the testing accuracy is higher than the decision tree above.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">dot_data</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">export_graphviz</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">out_file</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">graph</span> <span class="o">=</span> <span class="n">pydotplus</span><span class="o">.</span><span class="n">graph_from_dot_data</span><span class="p">(</span><span class="n">dot_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">create_png</span><span class="p">())</span>
</span></span><span class="line"><span class="cl"><span class="n">img</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_31.png"
	width="16665"
	height="2023"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_31_hu714c2296bf6f17c308a5ce87bc48a6a8_2369963_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_31_hu714c2296bf6f17c308a5ce87bc48a6a8_2369963_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="823"
		data-flex-basis="1977px"
	
></p>
<p>Updated confusion matrix:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">p</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cm</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&#34;YlGnBu&#34;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Actual Label&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted Label&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_32.png"
	width="666"
	height="593"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_32_hu81a98525a1bd73fae2ddf62eaf928b6f_27928_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_32_hu81a98525a1bd73fae2ddf62eaf928b6f_27928_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="112"
		data-flex-basis="269px"
	
></p>
<p>We can also plot the ROC curve:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## plot the roc curve</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;b--&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;orange&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive Rate&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Receiver Operating Characteristic Curve&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_33.png"
	width="691"
	height="547"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_33_hu3e3d794dccad83c715d1e01793221af2_33547_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_33_hu3e3d794dccad83c715d1e01793221af2_33547_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="126"
		data-flex-basis="303px"
	
></p>
<p>Observe that our decision tree analysis demonstrates the effectiveness of fine-tuning. Both the basic and optimized decision trees perform exceptionally well, which means there is great potential of using PCA-transformed features in classification tasks.</p>
<p>This analysis sets the stage for exploring more complex ensemble methods or different classifiers to see if performance can be enhanced further, following more steps below:</p>
<h3 id="bagging">
    <a href="#bagging">#</a>
    Bagging
</h3><p>Bagging is basically training multiple models on different subsets of the training dataset and then averaging their predictions to improve stability and accuracy.</p>
<p>Now we use bagging with decision tree classifier.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">t</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">22</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">bag</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">t</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">bag</span> <span class="o">=</span> <span class="n">bag</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">bag</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_pca</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;The test accuracy with basic bagging (using decision tree) is </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The test accuracy with basic bagging (using decision tree) is 0.9952077016052079</p>
<p>99.52%. demonstrates the effectiveness of bagging in reducing variance and avoiding overfitting.</p>
<p>The confusion matrix and the ROC curve are as follows:</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_34.png"
	width="666"
	height="593"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_34_hu0c8c9f5ec3786999242c12f4fc29fb43_27918_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_34_hu0c8c9f5ec3786999242c12f4fc29fb43_27918_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="112"
		data-flex-basis="269px"
	
></p>
<p>And ROC curve is</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_35.png"
	width="691"
	height="547"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_35_hu3e3d794dccad83c715d1e01793221af2_33547_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_35_hu3e3d794dccad83c715d1e01793221af2_33547_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="126"
		data-flex-basis="303px"
	
></p>
<p>The confusion matrix and the ROC curve shows us the model&rsquo;s high performance.</p>
<h2 id="k-nearest-neighbor-knn">
    <a href="#k-nearest-neighbor-knn">#</a>
    <strong>K Nearest Neighbor (KNN)</strong>
</h2><p>Next, let’s explore the K Nearest Neighbor (KNN) classifier, a simple method that classifies new cases based on a similarity measure (aka distance functions).</p>
<p>We first start with the basic KNN:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_pca</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;The test accuracy with basic bagging (using decision tree) is </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_36.png"
	width="666"
	height="593"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_36_hu98545244c588094674c414052eaa9c4f_27916_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_36_hu98545244c588094674c414052eaa9c4f_27916_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="112"
		data-flex-basis="269px"
	
></p>
<h4 id="optimizing-knn-parameters">
    <a href="#optimizing-knn-parameters">#</a>
    <strong>Optimizing KNN Parameters</strong>
</h4><p>To optimize the KNN classifier, we do a grid search to find the ideal number of neighbors.</p>
<p>Now we use cross validation to decide the best number of neighbors.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">clf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span> <span class="n">params</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;The best parameter is </span><span class="si">{</span><span class="n">clf</span><span class="o">.</span><span class="n">best_params_</span><span class="si">}</span><span class="s2"> and the corresponding train score is </span><span class="si">{</span><span class="n">clf</span><span class="o">.</span><span class="n">best_score_</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The best parameter is {&rsquo;n_neighbors&rsquo;: 1} and the corresponding score is 0.9929105088693813</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_pca</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;The test accuracy for KNN with best number of neighbors is </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The test accuracy for KNN with best number of neighbors is 0.9939566148561251, demonstrating high true positive rates and low false positive rates.</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_37.png"
	width="666"
	height="593"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_37_hu58f5d5483eccae6aef13758973785773_28042_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_37_hu58f5d5483eccae6aef13758973785773_28042_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="112"
		data-flex-basis="269px"
	
></p>
<p>ROC curve indicates an excellent performance:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## plot the roc curve</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;b--&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;orange&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive Rate&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Receiver Operating Characteristic Curve&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_38.png"
	width="691"
	height="547"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_38_huf0c23ae09ebaade4133d601c1c4bc768_33575_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_38_huf0c23ae09ebaade4133d601c1c4bc768_33575_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="126"
		data-flex-basis="303px"
	
></p>
<h2 id="discriminant-analysis">
    <a href="#discriminant-analysis">#</a>
    <strong>Discriminant Analysis</strong>
</h2><p>Linear Discriminant Analysis (LDA) is another technique we experimented.</p>
<p>LDA aims at finding a new axis that maximizes the separation between multiple classes.</p>
<h3 id="lda">
    <a href="#lda">#</a>
    LDA
</h3><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.discriminant_analysis</span> <span class="kn">import</span> <span class="n">LinearDiscriminantAnalysis</span> <span class="k">as</span> <span class="n">LDA</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.discriminant_analysis</span> <span class="kn">import</span> <span class="n">QuadraticDiscriminantAnalysis</span> <span class="k">as</span> <span class="n">QDA</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">clf</span> <span class="o">=</span> <span class="n">LDA</span><span class="p">(</span><span class="n">solver</span> <span class="o">=</span> <span class="s1">&#39;lsqr&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_pca</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;The test accuracy with LDA is </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## The test accuracy with LDA is 0.9929705888589665</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Initially, LDA provides an accuracy of about 99.30%.</p>
<h4 id="optimizing-lda-with-cross-validation">
    <a href="#optimizing-lda-with-cross-validation">#</a>
    <strong>Optimizing LDA with Cross Validation</strong>
</h4><p>Now we use cross validation with LDA to find the optimal shrinkage parameter.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;shrinkage&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mi">1</span><span class="p">]}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">clf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">LDA</span><span class="p">(</span><span class="n">solver</span> <span class="o">=</span> <span class="s1">&#39;lsqr&#39;</span><span class="p">),</span> <span class="n">params</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;The best parameter is </span><span class="si">{</span><span class="n">clf</span><span class="o">.</span><span class="n">best_params_</span><span class="si">}</span><span class="s2"> and the corresponding train score is </span><span class="si">{</span><span class="n">clf</span><span class="o">.</span><span class="n">best_score_</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The best parameter is {&lsquo;shrinkage&rsquo;: 0.25} and the corresponding train score is 0.992825693725328</p>
<p>Optimal results are achieved with a shrinkage of 0.25, slightly improving the accuracy to approximately 99.32%.</p>
<p>This parameter helps us regularize the LDA model, particularly handy when dealing with multicollinearity or multiple predictor variables.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">clf</span> <span class="o">=</span> <span class="n">LDA</span><span class="p">(</span><span class="n">solver</span> <span class="o">=</span> <span class="s1">&#39;lsqr&#39;</span><span class="p">,</span> <span class="n">shrinkage</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_pca</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;The test accuracy with LDA is </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## The test accuracy with LDA is 0.9932462520409678</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_39.png"
	width="666"
	height="593"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_39_hu38b170ae9e4c758d97a1d8430ac046f0_28071_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_39_hu38b170ae9e4c758d97a1d8430ac046f0_28071_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="112"
		data-flex-basis="269px"
	
></p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_40.png"
	width="691"
	height="547"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_40_huabe7a9aed8c19a92be3006c9728614f1_33523_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_40_huabe7a9aed8c19a92be3006c9728614f1_33523_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="126"
		data-flex-basis="303px"
	
></p>
<p>Both showcase effectiveness in classifying phishing URLs with high accuracy.</p>
<h3 id="quadratic-discriminant-analysis-qda">
    <a href="#quadratic-discriminant-analysis-qda">#</a>
    <strong>Quadratic Discriminant Analysis (QDA)</strong>
</h3><p>We also test Quadratic Discriminant Analysis (QDA), which allows for non-linear separation between classes.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">clf</span> <span class="o">=</span> <span class="n">QDA</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_pca</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;The test accuracy with LDA is </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## The test accuracy with LDA is 0.9796857439725185</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>However, QDA does not perform as well as LDA in this instance, with an accuracy around 97.97%. This suggests that the linear assumptions of LDA are sufficient for this dataset, and the more complex models might be overfitting or too sensitive to the specific data structure of our PCA-transformed features.</p>
<p>Hence, based on the test accuracy, LDA is more suitable than QDA in this case.</p>
<h2 id="support-vector-machine-svm">
    <a href="#support-vector-machine-svm">#</a>
    <strong>Support Vector Machine (SVM)</strong>
</h2><p>Support Vector Machines (SVMs) are renowned for their ability to handle high-dimensional data effectively.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>First we fit a Support Vector Classiﬁer to the data with regularization parameter C of 1.0 and a linear kernel.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">C</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel</span> <span class="o">=</span> <span class="s1">&#39;linear&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">svc</span> <span class="o">=</span> <span class="n">svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_pca</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;The test accuracy with basic SVM is </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The test accuracy with basic SVM is 0.9967768612566 - an exceptionally high test accuracy.</p>
<p>To further analyze the performance, we visualize the confusion matrix and the Receiver Operating Characteristic (ROC) curve:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">p</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cm</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&#34;YlGnBu&#34;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Actual Label&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted Label&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## plot the roc curve</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;b--&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;orange&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive Rate&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Receiver Operating Characteristic Curve&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_41.png"
	width="666"
	height="593"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_41_hu0c0f69784e562bb4355e28d45ed0ec35_27836_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_41_hu0c0f69784e562bb4355e28d45ed0ec35_27836_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="112"
		data-flex-basis="269px"
	
></p>
<p>The confusion matrix reveals a high number of correct predictions with very few false positives and negatives. Good news.</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_42.png"
	width="691"
	height="547"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_42_huff4ba22fe4c27e05e46a16f4fd76747e_33414_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_42_huff4ba22fe4c27e05e46a16f4fd76747e_33414_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="126"
		data-flex-basis="303px"
	
></p>
<p>ROC curve approaches the top left corner, meaning an excellent model performance!</p>
<h4 id="exploring-svm-with-rbf-kernel">
    <a href="#exploring-svm-with-rbf-kernel">#</a>
    <strong>Exploring SVM with RBF Kernel</strong>
</h4><p>Now we explore the SVM with a radial basis function (RBF) kernel, which can handle non-linear data distributions:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">C</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel</span> <span class="o">=</span> <span class="s1">&#39;rbf&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">svc</span> <span class="o">=</span> <span class="n">svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_pca</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;The test accuracy with basic SVM is </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The test accuracy with basic SVM is 0.9910515490150342</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_43.png"
	width="666"
	height="593"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_43_huc8ba172900771b24b95c8da65b156eea_27890_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_43_huc8ba172900771b24b95c8da65b156eea_27890_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="112"
		data-flex-basis="269px"
	
></p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_44.png"
	width="691"
	height="547"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_44_hua8d287a3a646da61c9a0034ac6ab6bda_33355_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_44_hua8d287a3a646da61c9a0034ac6ab6bda_33355_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="126"
		data-flex-basis="303px"
	
></p>
<p>The confusion matrix for the RBF model shows slightly more misclassifications than the linear model, which is also reflected in the ROC curve.</p>
<h3 id="conclusion-on-svm-performance">
    <a href="#conclusion-on-svm-performance">#</a>
    <strong>Conclusion on SVM Performance</strong>
</h3><p>The comparative analysis between linear and RBF kernels in SVM shows the importance of choosing the right kernel based on the data&rsquo;s characteristics.</p>
<p>In our specific case, the simpler linear kernel proved more effective, which shows us an interesting observation that more complex models are not always superior!</p>
<hr>
<h2 id="artificial-neural-networks-classification">
    <a href="#artificial-neural-networks-classification">#</a>
    <strong>Artificial Neural Networks Classification</strong>
</h2><h3 id="introduction-to-the-ann-architecture">
    <a href="#introduction-to-the-ann-architecture">#</a>
    Introduction to the ANN Architecture
</h3><p>The ANN has three types of layers: the input layer, the hidden layers, and the output layer. Initially, the network weights are assigned randomly. As input is fed into the input layer, it progresses forward, with each subsequent hidden layer receiving the input, modified by these weights. This process continues until it reaches the output layer, where a result is produced. This result is then compared to the actual value, triggering the backpropagation algorithm to adjust the network&rsquo;s weights and improve future results. The neurons in each layer facilitate this learning process. Each neuron contains an activation function that determines whether and how to transmit its received signal based on the input from the previous layer. We&rsquo;ll explore activation functions in greater detail shortly.</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_45.png"
	width="659"
	height="394"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_45_hua56ac72673bb183f7b11bde6c36ecc16_47802_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_45_hua56ac72673bb183f7b11bde6c36ecc16_47802_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
		alt="Source: https://www.sciencedirect.com/topics/earth-and-planetary-sciences/artificial-neural-network"
	
	
		class="gallery-image" 
		data-flex-grow="167"
		data-flex-basis="401px"
	
></p>
<p>Source: <a class="link" href="https://www.sciencedirect.com/topics/earth-and-planetary-sciences/artificial-neural-network"  target="_blank" rel="noopener"
    >https://www.sciencedirect.com/topics/earth-and-planetary-sciences/artificial-neural-network</a></p>
<p>Here’s a breakdown of the steps involved in this process:</p>
<ol>
<li><strong>Assign random weights</strong> to all linkages to initiate the algorithm.</li>
<li><strong>Compute the activation rate</strong> of hidden nodes using the inputs and their linkages from the input layer.</li>
<li><strong>Determine the activation rate</strong> of output nodes, using the activation rates of hidden nodes and their linkages to the output.</li>
<li><strong>Calculate the error rate</strong> at the output node and adjust the linkages between hidden and output nodes to minimize this error.</li>
<li><strong>Propagate the error</strong> back from the output nodes to the hidden nodes, recalibrating the linkages between the input and hidden nodes.</li>
<li><strong>Repeat the process</strong> until the convergence criteria are met.</li>
<li><strong>Evaluate</strong> using the final linkage weights to determine the activation rate of the output nodes.</li>
</ol>
<h3 id="split-data-to-train-validation-and-test">
    <a href="#split-data-to-train-validation-and-test">#</a>
    <strong>Split Data to Train, Validation, and Test</strong>
</h3><p>We will use the training set to fit the model, the validation set to tune the parameters (starting with the baseline model first) and the testing set for the final evaluation.</p>
<p>For the purpose of this project, we will use 70% for training, 15% for validation and 15% for testing.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Set the ratios for train, validation and test</span>
</span></span><span class="line"><span class="cl"><span class="n">train_ratio</span> <span class="o">=</span> <span class="mf">0.7</span>
</span></span><span class="line"><span class="cl"><span class="n">validation_ratio</span> <span class="o">=</span> <span class="mf">0.15</span>
</span></span><span class="line"><span class="cl"><span class="n">test_ratio</span> <span class="o">=</span> <span class="mf">0.15</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## we can set the seed 42 for reproducibility</span>
</span></span><span class="line"><span class="cl"><span class="n">random_state</span><span class="o">=</span> <span class="mi">42</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Split the data into train, validation and test</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df_features_encoded</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                    <span class="n">df_target</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                    <span class="n">test_size</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="n">train_ratio</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                    <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">X_val</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                <span class="n">y_test</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                <span class="n">test_size</span><span class="o">=</span><span class="n">test_ratio</span><span class="o">/</span><span class="p">(</span><span class="n">test_ratio</span> <span class="o">+</span> <span class="n">validation_ratio</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                                                <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## get shapes</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Datasets after splitting:</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;X_train: </span><span class="si">{</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;X_val: </span><span class="si">{</span><span class="n">X_val</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;X_test: </span><span class="si">{</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Datasets after splitting:</p>
<ul>
<li>X_train: (165056, 2740)</li>
<li>X_val: (35369, 2740)</li>
<li>X_test: (35370, 2740)</li>
</ul>
<h3 id="feature-scaling">
    <a href="#feature-scaling">#</a>
    Feature Scaling
</h3><p>We don&rsquo;t want an independent variable to dominate the others in the model. So, we will scale the features to standardize the range of independent features of data. It also makes sure the gradient descent used in training converges more efficiently.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_val</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="using-ann-for-binary-classification-the-baseline-model">
    <a href="#using-ann-for-binary-classification-the-baseline-model">#</a>
    Using ANN for Binary Classification: The Baseline Model
</h3><p>Let’s first set some parameters:</p>
<ul>
<li>input_shape: 2740 - number of input features each input example has.</li>
<li>n_batch_size: 1650 - how many rows/instances of data the network processes at once (in training)</li>
<li>n_steps_per_epoch: 100 - number of batches or steps the model trains on in each epoch (i.e., how many times the model will update its weights per epoch)</li>
<li>n_validation_steps: 21 - and for the for the validation dataset</li>
<li>n_epochs: 25 - umber of steps (batches) to evaluate the test set</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">input_shape</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## num of samples per mini-batch of training data</span>
</span></span><span class="line"><span class="cl"><span class="c1">## smaller batch size means noiser gradient, but can speed up training</span>
</span></span><span class="line"><span class="cl"><span class="n">n_batch_size</span> <span class="o">=</span> <span class="mi">100</span>
</span></span><span class="line"><span class="cl"><span class="n">n_steps_per_epoch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">n_batch_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">n_validation_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">X_val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">n_batch_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">n_test_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">n_batch_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## number of epochs is how often a complete </span>
</span></span><span class="line"><span class="cl"><span class="c1">## run through the training data is performed</span>
</span></span><span class="line"><span class="cl"><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">25</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;input_shape: </span><span class="si">{</span><span class="n">input_shape</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;n_batch_size: </span><span class="si">{</span><span class="n">n_batch_size</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;n_steps_per_epoch: </span><span class="si">{</span><span class="n">n_steps_per_epoch</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;n_validation_steps: </span><span class="si">{</span><span class="n">n_validation_steps</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;n_test_steps: </span><span class="si">{</span><span class="n">n_test_steps</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;n_epochs: </span><span class="si">{</span><span class="n">n_epochs</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="build-the-baseline-model">
    <a href="#build-the-baseline-model">#</a>
    Build the Baseline Model
</h4><p>Let’s initialize the layers, neurons, activation functions, and finally compile the model with a loss function and optimizer.</p>
<p>Here, we used 2 fully connected layers with 16 neurons each. Because this is a binary classification problem, the output layer has 1 neuron and uses a sigmoid activation function.</p>
<p><strong>Hidden layers:</strong></p>
<p>For the hidden layers, we use ReLU function. ReLU works in a way that its outputs the input directly if it is positive; otherwise, it outputs zero. It’s simple, so this makes ReLU very straightforward and efficient computationally. Specifically it prevents our activation levels from being too high or too low (which would be problematic with some other functions that squish values into a tiny range) so the data is generates is more useful for our purpose.</p>
<p><strong>Output layer:</strong></p>
<p>The sigmoid function squishes any real value into range between 0 and 1. Think of it a kind of translator that takes a wide range of input numbers and converts them into a language of probabilities. Handy when we need to predict probabilities for classification tasks like this one.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">models</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">    <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,)),</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">		<span class="c1"># 2 fully connected layers with 16 neurons each</span>
</span></span><span class="line"><span class="cl">		<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">		<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">		
</span></span><span class="line"><span class="cl">		<span class="c1"># because this is a binary classification problem,</span>
</span></span><span class="line"><span class="cl">		<span class="c1"># the output layer has 1 neuron and uses a sigmoid activation function</span>
</span></span><span class="line"><span class="cl">		<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Here is the layer structure:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">Model: &#34;sequential&#34;
</span></span><span class="line"><span class="cl">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
</span></span><span class="line"><span class="cl">┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
</span></span><span class="line"><span class="cl">┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
</span></span><span class="line"><span class="cl">│ dense (Dense)                   │ (None, 16)             │        43,856 │
</span></span><span class="line"><span class="cl">├─────────────────────────────────┼────────────────────────┼───────────────┤
</span></span><span class="line"><span class="cl">│ dense_1 (Dense)                 │ (None, 16)             │           272 │
</span></span><span class="line"><span class="cl">├─────────────────────────────────┼────────────────────────┼───────────────┤
</span></span><span class="line"><span class="cl">│ dense_2 (Dense)                 │ (None, 1)              │            17 │
</span></span><span class="line"><span class="cl">└─────────────────────────────────┴────────────────────────┴───────────────┘
</span></span><span class="line"><span class="cl"> Total params: 44,145 (172.44 KB)
</span></span><span class="line"><span class="cl"> Trainable params: 44,145 (172.44 KB)
</span></span><span class="line"><span class="cl"> Non-trainable params: 0 (0.00 B)
</span></span></code></pre></td></tr></table>
</div>
</div><p>Compile the model:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Configure the model for training</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Let’s also store the callbacks, so we may use the model later again.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## store checkpoints</span>
</span></span><span class="line"><span class="cl"><span class="n">checkpoint_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;./</span><span class="si">{</span><span class="n">checkpoint_no</span><span class="si">}</span><span class="s1">&#39;</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="n">keras_callbacks</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="n">ModelCheckpoint</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">filepath</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="n">model_name</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">]</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="fit-the-baseline-model">
    <a href="#fit-the-baseline-model">#</a>
    Fit the Baseline Model
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">X_train</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">y_train</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch_size</span><span class="o">=</span><span class="n">n_batch_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">n_steps_per_epoch</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">validation_steps</span><span class="o">=</span><span class="n">n_validation_steps</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">callbacks</span><span class="o">=</span><span class="n">keras_callbacks</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Wait until all the epochs have been finished:</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_46.png"
	width="1145"
	height="1024"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_46_hu8cb4afd8ef2503e5b21e2adfed93a42a_326426_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_46_hu8cb4afd8ef2503e5b21e2adfed93a42a_326426_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="111"
		data-flex-basis="268px"
	
></p>
<p>Get the best model values</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Get the best model values</span>
</span></span><span class="line"><span class="cl"><span class="n">df_history</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df_history</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_history</span><span class="o">.</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl"><span class="n">df_history</span> <span class="o">=</span> <span class="n">df_history</span><span class="p">[[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df_history</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">col</span> <span class="o">!=</span> <span class="s1">&#39;epoch&#39;</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl"><span class="n">df_history</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">checkpoint_no</span><span class="si">}</span><span class="s2">/history_df_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">.csv&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df_history</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">values_of_best_model</span> <span class="o">=</span> <span class="n">df_history</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_history</span><span class="o">.</span><span class="n">val_loss</span><span class="o">.</span><span class="n">idxmin</span><span class="p">()]</span>
</span></span><span class="line"><span class="cl"><span class="n">values_of_best_model</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_47.png"
	width="448"
	height="189"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_47_hu74f2c702628bf909cbb24de961ab5fb7_22139_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_47_hu74f2c702628bf909cbb24de961ab5fb7_22139_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="237"
		data-flex-basis="568px"
	
></p>
<p><code>values_of_best_model</code>:</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_48.png"
	width="507"
	height="76"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_48_hu903bc8fa740443c071d3eeea70a858a3_8219_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_48_hu903bc8fa740443c071d3eeea70a858a3_8219_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="667"
		data-flex-basis="1601px"
	
></p>
<p>Also save the class assignments, so we can use them later.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">class_assignment</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;phishing&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;legitimate&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">df_class_assignment</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">class_assignment</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Category&#39;</span><span class="p">,</span> <span class="s1">&#39;Class&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">df_class_assignment</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">checkpoint_no</span><span class="si">}</span><span class="s2">/class_assignment_df_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">.csv&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## save the scaler</span>
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">checkpoint_no</span><span class="si">}</span><span class="s1">/scaler.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">pk</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">scaler</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="validation">
    <a href="#validation">#</a>
    Validation
</h4><p>Going ahead to validation, where we will compare the models predictions on the validation set. We are going to get both the accuracy (how often the model&rsquo;s predictions match the true labels) and loss (how far off the predictions are from the actual results).</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">accuracy = history.history[&#39;accuracy&#39;]
</span></span><span class="line"><span class="cl">validation_accuracy = history.history[&#39;val_accuracy&#39;]
</span></span><span class="line"><span class="cl">loss = history.history[&#39;loss&#39;]
</span></span><span class="line"><span class="cl">val_loss = history.history[&#39;val_loss&#39;]
</span></span><span class="line"><span class="cl">epochs = range(1, len(accuracy) + 1)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">plt.figure(figsize=(12, 6))
</span></span><span class="line"><span class="cl">plt.plot(epochs, accuracy, &#39;bo&#39;, label=&#39;Training acc&#39;)
</span></span><span class="line"><span class="cl">plt.plot(epochs, validation_accuracy, &#39;b&#39;, label=&#39;Validation acc&#39;)
</span></span><span class="line"><span class="cl">plt.title(&#39;Training and validation accuracy&#39;)
</span></span><span class="line"><span class="cl">plt.legend()
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">plt.figure(figsize=(12, 6))
</span></span><span class="line"><span class="cl">plt.plot(epochs, loss, &#39;bo&#39;, label=&#39;Training loss&#39;)
</span></span><span class="line"><span class="cl">plt.plot(epochs, val_loss, &#39;b&#39;, label=&#39;Validation loss&#39;)
</span></span><span class="line"><span class="cl">plt.title(&#39;Training and validation loss&#39;)
</span></span><span class="line"><span class="cl">plt.legend()
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">plt.show()
</span></span></code></pre></td></tr></table>
</div>
</div><p>Plot the training accuracy (<strong><code>accuracy</code></strong>) and validation accuracy (<strong><code>validation_accuracy</code></strong>) are plotted against the number of epochs:</p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_49.png"
	width="999"
	height="528"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_49_huf6e26c26a648cf96275029101d509d51_35446_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_49_huf6e26c26a648cf96275029101d509d51_35446_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="189"
		data-flex-basis="454px"
	
></p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_50.png"
	width="990"
	height="528"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_50_hucae92a2fb1b4325b7e5eba49cef9c1f7_27089_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_50_hucae92a2fb1b4325b7e5eba49cef9c1f7_27089_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="187"
		data-flex-basis="450px"
	
></p>
<p>Not much overfitting observed.</p>
<h4 id="test-the-baseline-model">
    <a href="#test-the-baseline-model">#</a>
    Test the Baseline Model
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Loading the saved model</span>
</span></span><span class="line"><span class="cl"><span class="n">model_reloaded</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">checkpoint_no</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">root_directory</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">checkpoint_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_directory</span><span class="p">,</span> <span class="n">checkpoint_no</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">saved_model_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">.keras&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">model_reloaded</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">saved_model_name</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## Delete the saved model</span>
</span></span><span class="line"><span class="cl"><span class="n">saved_model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">saved_model_path</span><span class="p">,</span> <span class="n">ignore_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## load the best model</span>
</span></span><span class="line"><span class="cl"><span class="n">best_model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">saved_model_name</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">test_score</span><span class="p">,</span> <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">n_test_steps</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test Accuracy:&#39;</span><span class="p">,</span> <span class="n">test_accuracy</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="mi">101</span><span class="o">/</span><span class="mi">101</span> <span class="err">━━━━━━━━━━━━━━━━━━━━</span> <span class="mi">0</span><span class="n">s</span> <span class="mi">2</span><span class="n">ms</span><span class="o">/</span><span class="n">step</span> <span class="o">-</span> <span class="n">accuracy</span><span class="p">:</span> <span class="mf">0.9997</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.0022</span>  
</span></span><span class="line"><span class="cl"><span class="n">Test</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.9996324777603149</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The test accuracy is pretty high with a very low loss value. Let’s proceed with the following steps to further improve the model.</p>
<h3 id="improve-the-ann-model-by-tuning-the-ann-and-avoiding-overfitting">
    <a href="#improve-the-ann-model-by-tuning-the-ann-and-avoiding-overfitting">#</a>
    Improve the ANN Model by Tuning the ANN and Avoiding Overfitting
</h3><h4 id="set-parameters">
    <a href="#set-parameters">#</a>
    Set Parameters
</h4><p>Instead of an arbitrary <code>n_batch_size</code>, here we use 1% of the training data. Smaller batch sizes can introduce more noise into the gradient descent process.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">input_shape</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">sample_size</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## num of samples per mini-batch of training data</span>
</span></span><span class="line"><span class="cl"><span class="c1">## smaller batch size means noiser gradient, but can speed up training</span>
</span></span><span class="line"><span class="cl"><span class="n">n_batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.01</span> <span class="o">*</span> <span class="n">sample_size</span><span class="p">)</span> <span class="c1"># here we use 1% of the training data</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">n_steps_per_epoch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">n_batch_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">n_validation_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">X_val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">n_batch_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">n_test_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">n_batch_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## number of epochs is how often a complete</span>
</span></span><span class="line"><span class="cl"><span class="c1">## run through the training data is performed</span>
</span></span><span class="line"><span class="cl"><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">25</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;input_shape: </span><span class="si">{</span><span class="n">input_shape</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;sample_size: </span><span class="si">{</span><span class="n">sample_size</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;n_batch_size: </span><span class="si">{</span><span class="n">n_batch_size</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;n_steps_per_epoch: </span><span class="si">{</span><span class="n">n_steps_per_epoch</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;n_validation_steps: </span><span class="si">{</span><span class="n">n_validation_steps</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;n_test_steps: </span><span class="si">{</span><span class="n">n_test_steps</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;n_epochs: </span><span class="si">{</span><span class="n">n_epochs</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="implementing-early-stoping">
    <a href="#implementing-early-stoping">#</a>
    Implementing Early Stoping
</h4><p>We implement early stopping to prevent overfitting. What is does is automatically stopping the training process when the validation score stops improving.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">early_stopping</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="implementing-a-learning-rate-schedule">
    <a href="#implementing-a-learning-rate-schedule">#</a>
    Implementing <strong>a Learning Rate Schedule</strong>
</h4><p>Instead of a fixed <code>lr</code> let&rsquo;s use a learning rate schedule. This will reduce the learning rate when as training goes on.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">reduce_lr</span> <span class="o">=</span> <span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="implementing-the-weight-regularization">
    <a href="#implementing-the-weight-regularization">#</a>
    Implementing <strong>the Weight Regularization</strong>
</h4><p>A learning rate schedule adjusts the learning rate over time. It reduces the learning rate if the validation loss stops improving.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">regularizer</span><span class="o">=</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="build-the-model">
    <a href="#build-the-model">#</a>
    Build the Model
</h3><p>Here is where we can rename our model.</p>
<p>For this project, let&rsquo;s name our model <code>URL_ANN_2FC_F16_16_epoch_25</code> because of the parameters we set above.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">checkpoint_no</span> <span class="o">=</span> <span class="s1">&#39;checkpoint_1_ANN&#39;</span>
</span></span><span class="line"><span class="cl"><span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;URL_ANN_2FC_F16_16_epoch_25.keras&#39;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Note that <code>Kera</code> requires models to have a filename ending in <code>.keras</code>.</p>
<h4 id="implementing-dropout-layers">
    <a href="#implementing-dropout-layers">#</a>
    Implementing Dropout Layers
</h4><p>Incorporate the changes we have made, and also implement some dropout layers.</p>
<p>Dropout is a regularization technique used to prevent overfitting. The dropout layer randomly sets a fraction <code>p</code> of the input units to 0 at each update during training time, which helps us to make the activation of the neurons sparse, thus reducing overfitting.</p>
<p>We have tried setting them at different levels from 0.1 to 0.5. Here in the example below, we set <code>p</code> to 0.5, which means we randomly exclude half of the neuron outputs from each update cycle.</p>
<p>Note that in some cases setting it as high as 0.5 or above might lead to underfitting.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">create_model</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,)))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 2 fully connected layers with 16 neurons each:</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">regularizer</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                        <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># add some dropouts to prevent overfitting</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">regularizer</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                        <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># add some dropouts to prevent overfitting</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># because this is a binary classification problem,</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># the output layer has 1 neuron and uses a sigmoid activation function</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Configure the model for training</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">model</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Same as before:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">Model</span><span class="p">:</span> <span class="s2">&#34;sequential&#34;</span>
</span></span><span class="line"><span class="cl"><span class="err">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓</span>
</span></span><span class="line"><span class="cl"><span class="err">┃</span> <span class="n">Layer</span> <span class="p">(</span><span class="nb">type</span><span class="p">)</span>                         <span class="err">┃</span> <span class="n">Output</span> <span class="n">Shape</span>                <span class="err">┃</span>         <span class="n">Param</span> <span class="c1"># ┃</span>
</span></span><span class="line"><span class="cl"><span class="err">┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩</span>
</span></span><span class="line"><span class="cl"><span class="err">│</span> <span class="n">dense</span> <span class="p">(</span><span class="n">Dense</span><span class="p">)</span>                        <span class="err">│</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>                  <span class="err">│</span>          <span class="mi">43</span><span class="p">,</span><span class="mi">856</span> <span class="err">│</span>
</span></span><span class="line"><span class="cl"><span class="err">├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤</span>
</span></span><span class="line"><span class="cl"><span class="err">│</span> <span class="n">dropout</span> <span class="p">(</span><span class="n">Dropout</span><span class="p">)</span>                    <span class="err">│</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>                  <span class="err">│</span>               <span class="mi">0</span> <span class="err">│</span>
</span></span><span class="line"><span class="cl"><span class="err">├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤</span>
</span></span><span class="line"><span class="cl"><span class="err">│</span> <span class="n">dense_1</span> <span class="p">(</span><span class="n">Dense</span><span class="p">)</span>                      <span class="err">│</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>                  <span class="err">│</span>             <span class="mi">272</span> <span class="err">│</span>
</span></span><span class="line"><span class="cl"><span class="err">├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤</span>
</span></span><span class="line"><span class="cl"><span class="err">│</span> <span class="n">dropout_1</span> <span class="p">(</span><span class="n">Dropout</span><span class="p">)</span>                  <span class="err">│</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>                  <span class="err">│</span>               <span class="mi">0</span> <span class="err">│</span>
</span></span><span class="line"><span class="cl"><span class="err">├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤</span>
</span></span><span class="line"><span class="cl"><span class="err">│</span> <span class="n">dense_2</span> <span class="p">(</span><span class="n">Dense</span><span class="p">)</span>                      <span class="err">│</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>                   <span class="err">│</span>              <span class="mi">17</span> <span class="err">│</span>
</span></span><span class="line"><span class="cl"><span class="err">└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘</span>
</span></span><span class="line"><span class="cl"> <span class="n">Total</span> <span class="n">params</span><span class="p">:</span> <span class="mi">44</span><span class="p">,</span><span class="mi">145</span> <span class="p">(</span><span class="mf">172.44</span> <span class="n">KB</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"> <span class="n">Trainable</span> <span class="n">params</span><span class="p">:</span> <span class="mi">44</span><span class="p">,</span><span class="mi">145</span> <span class="p">(</span><span class="mf">172.44</span> <span class="n">KB</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"> <span class="n">Non</span><span class="o">-</span><span class="n">trainable</span> <span class="n">params</span><span class="p">:</span> <span class="mi">0</span> <span class="p">(</span><span class="mf">0.00</span> <span class="n">B</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Then, we set up the callbacks following the same steps. Codes are omitted here.</p>
<h4 id="fit-the-model">
    <a href="#fit-the-model">#</a>
    <strong>Fit the Model</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">batch_size</span><span class="o">=</span><span class="n">n_batch_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">n_steps_per_epoch</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">validation_steps</span><span class="o">=</span><span class="n">n_validation_steps</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">keras_callbacks</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">,</span> <span class="n">reduce_lr</span><span class="p">])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Get the best model values</span>
</span></span><span class="line"><span class="cl"><span class="n">df_history</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df_history</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_history</span><span class="o">.</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl"><span class="n">df_history</span> <span class="o">=</span> <span class="n">df_history</span><span class="p">[[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df_history</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">col</span> <span class="o">!=</span> <span class="s1">&#39;epoch&#39;</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl"><span class="n">df_history</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">checkpoint_no</span><span class="si">}</span><span class="s2">/history_df_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">.csv&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df_history</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">values_of_best_model</span> <span class="o">=</span> <span class="n">df_history</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_history</span><span class="o">.</span><span class="n">val_loss</span><span class="o">.</span><span class="n">idxmin</span><span class="p">()]</span>
</span></span><span class="line"><span class="cl"><span class="n">values_of_best_model</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">epoch</span>            <span class="mf">12.000000</span>
</span></span><span class="line"><span class="cl"><span class="n">accuracy</span>          <span class="mf">1.000000</span>
</span></span><span class="line"><span class="cl"><span class="n">loss</span>              <span class="mf">0.048962</span>
</span></span><span class="line"><span class="cl"><span class="n">val_accuracy</span>      <span class="mf">1.000000</span>
</span></span><span class="line"><span class="cl"><span class="n">val_loss</span>          <span class="mf">0.022055</span>
</span></span><span class="line"><span class="cl"><span class="n">learning_rate</span>     <span class="mf">0.001000</span>
</span></span><span class="line"><span class="cl"><span class="n">Name</span><span class="p">:</span> <span class="mi">11</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">float64</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="validation-1">
    <a href="#validation-1">#</a>
    Validation
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">accuracy</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">validation_accuracy</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="s1">&#39;bo&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training acc&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">validation_accuracy</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation acc&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation accuracy&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;bo&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training loss&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation loss&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_51.png"
	width="990"
	height="528"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_51_hu7e36b48808194c573500699e7cf0b6e8_29560_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_51_hu7e36b48808194c573500699e7cf0b6e8_29560_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="187"
		data-flex-basis="450px"
	
></p>
<p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_52.png"
	width="990"
	height="528"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_52_hu0172e9cfa13b6499d5d13ed11557a3d9_29192_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_52_hu0172e9cfa13b6499d5d13ed11557a3d9_29192_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="187"
		data-flex-basis="450px"
	
></p>
<p>The validation loss generally remains low and close to the training loss, which suggests that the model is not overfitting and has learned the underlying patterns in the data well.</p>
<h4 id="testing-the-model">
    <a href="#testing-the-model">#</a>
    <strong>Testing the Model</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">test_score</span><span class="p">,</span> <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">n_test_steps</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Test Score: </span><span class="si">{</span><span class="n">test_score</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Test Accuracy: </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="mi">1685</span><span class="o">/</span><span class="mi">1685</span> <span class="err">━━━━━━━━━━━━━━━━━━━━</span> <span class="mi">3</span><span class="n">s</span> <span class="mi">2</span><span class="n">ms</span><span class="o">/</span><span class="n">step</span> <span class="o">-</span> <span class="n">accuracy</span><span class="p">:</span> <span class="mf">0.9988</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.0276</span>
</span></span><span class="line"><span class="cl"><span class="n">Test</span> <span class="n">Score</span><span class="p">:</span> <span class="mf">0.02890169993042946</span>
</span></span><span class="line"><span class="cl"><span class="n">Test</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.9984450340270996</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The model is performing very well with high accuracy and low loss on both the training and validation datasets.</p>
<h4 id="make-predictions">
    <a href="#make-predictions">#</a>
    <strong>Make Predictions</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## Make predictions</span>
</span></span><span class="line"><span class="cl"><span class="n">y_pred_prob</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">y_pred_prob</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">array</span><span class="p">([[</span><span class="mf">1.2841106e-06</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">       <span class="p">[</span><span class="mf">9.9997938e-01</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">       <span class="p">[</span><span class="mf">1.0000000e+00</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">       <span class="o">...</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">       <span class="p">[</span><span class="mf">6.7629302e-09</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">       <span class="p">[</span><span class="mf">1.5825824e-06</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">       <span class="p">[</span><span class="mf">9.9999905e-01</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>We need to convert the predictions to binary values.</p>
<p>Let&rsquo;s use a threshold of 0.5. If the prediction is greater than 0.5, we will consider it as <code>1</code>, otherwise <code>0</code>.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_pred_prob</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="evaluation">
    <a href="#evaluation">#</a>
    <strong>Evaluation</strong>
</h3><h4 id="confusion-matrix">
    <a href="#confusion-matrix">#</a>
    Confusion Matrix
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">p</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cm</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&#34;YlGnBu&#34;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Actual Label&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted Label&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_53.png"
	width="666"
	height="593"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_53_hu7841ac6f4a6204e6311308ccef12a872_29016_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_53_hu7841ac6f4a6204e6311308ccef12a872_29016_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="112"
		data-flex-basis="269px"
	
></p>
<h4 id="classification-report">
    <a href="#classification-report">#</a>
    <strong>Classification Report</strong>
</h4><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">              <span class="n">precision</span>    <span class="n">recall</span>  <span class="n">f1</span><span class="o">-</span><span class="n">score</span>   <span class="n">support</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">           <span class="mi">0</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>     <span class="mi">15090</span>
</span></span><span class="line"><span class="cl">           <span class="mi">1</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>     <span class="mi">20280</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">accuracy</span>                           <span class="mf">1.00</span>     <span class="mi">35370</span>
</span></span><span class="line"><span class="cl">   <span class="n">macro</span> <span class="n">avg</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>     <span class="mi">35370</span>
</span></span><span class="line"><span class="cl"><span class="n">weighted</span> <span class="n">avg</span>       <span class="mf">1.00</span>      <span class="mf">1.00</span>      <span class="mf">1.00</span>     <span class="mi">35370</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="roc-curve">
    <a href="#roc-curve">#</a>
    ROC Curve
</h4><p>Let&rsquo;s plot the ROC curve to see how well the model performs. The ROC curve plots the true positive rate (TPR) against the false positive rate (FPR) at diffrent values of threshold. The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## calculate the probabilities using the classifier</span>
</span></span><span class="line"><span class="cl"><span class="n">y_pred_proba</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## calculate the roc curve</span>
</span></span><span class="line"><span class="cl"><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## plot the roc curve</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;k--&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;ANN&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive Rate&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Receiver Operating Characteristic (ROC) Curve&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_54.png"
	width="691"
	height="547"
	srcset="/~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_54_hu459a3e036f00a67fb981b37fd5f75c46_32627_480x0_resize_box_3.png 480w, /~jimy/pennfish/p/pennfish-detecting-phishing-websites-a-machine-learning-approach/Untitled_54_hu459a3e036f00a67fb981b37fd5f75c46_32627_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="126"
		data-flex-basis="303px"
	
></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## area under the curve</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;ROC AUC Score: </span><span class="si">{</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">)</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">ROC AUC Score: 0.9998084438797851
</span></span></code></pre></td></tr></table>
</div>
</div><p>We observed that the AUC score is very close to 1, which is a good sign that the model is doing a good job to classify the URLs to be phishing or not.</p>
<h3 id="conclusion-of-ann">
    <a href="#conclusion-of-ann">#</a>
    Conclusion of ANN
</h3><p>Overall, the model is performing very well with high accuracy and low loss on both the training and validation datasets. The consistent high accuracy and low loss over epochs without a widening gap between training and validation metrics indicate that the model is stable and generalizes well.</p>
<h2 id="challenges">
    <a href="#challenges">#</a>
    Challenges
</h2><p>Have you attempted challenging analysis? How much time would have been required to
complete your project?</p>
<p>Big Data</p>
<p>Our project applied artificial neural network classification (ANN), which includes the baseline model, tuning ANN and avoiding overfitting, build the model and evaluation. We made modifications of the ANN model to obtain accurate prediction of the phishing websites.</p>
<p>On average, each team member spent 20 hours on the project.</p>
<h2 id="conclusion">
    <a href="#conclusion">#</a>
    Conclusion
</h2><p>Our project is applied logistic regression, PCA to reduce dimensionality, logistic regression with PCA, ridge regression, linear regression (unregularized), linear regression (unregularized) with PCA, random forest classifier, random forest regression, and decision tree classifier which are taught in class. We also extend the scope to k-nearest neighbor, discriminant analysis, support vector machine (SVM), and artificial neural networks classification (ANN).</p>
<h2 id="references">
    <a href="#references">#</a>
    References
</h2><ul>
<li>Dutta, A. (2021). Detecting phishing websites using machine learning technique. <em>PLoS ONE</em>, 16. <a class="link" href="https://doi.org/10.1371/journal.pone.0258361"  target="_blank" rel="noopener"
    >https://doi.org/10.1371/journal.pone.0258361</a>.</li>
<li>Gastellier-Prevost, S., Granadillo, G., &amp; Laurent, M. (2011). Decisive Heuristics to Differentiate Legitimate from Phishing Sites. <em>2011 Conference on Network and Information Systems Security</em>, 1-9. <a class="link" href="https://doi.org/10.1109/SAR-SSI.2011.5931389"  target="_blank" rel="noopener"
    >https://doi.org/10.1109/SAR-SSI.2011.5931389</a>.</li>
<li>Levy, E. (2004). Interface Illusions. <em>IEEE Secur. Priv.</em>, 2, 66-69. <a class="link" href="https://doi.org/10.1109/MSP.2004.104"  target="_blank" rel="noopener"
    >https://doi.org/10.1109/MSP.2004.104</a>.</li>
<li>Michael Fuchs Python. (2021, February 16). <em>NN – Artificial neural network for binary classification</em>. https://michael-fuchs-python.netlify.app/2021/02/16/nn-artificial-neural-network-for-binary-classification/#encoding</li>
</ul>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/~jimy/pennfish/tags/phishing/">Phishing</a>
        
    </section>


    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    </footer>


    
</article>

    

    

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
        2024 PennFish
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.25.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/~jimy/pennfish/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
